{"componentChunkName":"component---src-templates-tag-page-template-index-tsx","path":"/tags/audio/en/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"id":"32139abc-0c9c-5c23-9579-00629bcca354","tableOfContents":"<ul>\n<li>\n<p><a href=\"#compressor\">Compressor</a></p>\n<ul>\n<li><a href=\"#implementing-compressor\">Implementing Compressor</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#reverb\">Reverb</a></p>\n<ul>\n<li><a href=\"#convolution-reverb\">Convolution Reverb</a></li>\n<li><a href=\"#implementing-convolution-reverb\">Implementing Convolution Reverb</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#delay\">Delay</a></p>\n<ul>\n<li><a href=\"#implementing-delay\">Implementing Delay</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#filter\">Filter</a></p>\n<ul>\n<li><a href=\"#implementing-filter\">Implementing Filter</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#eq\">EQ</a></p>\n<ul>\n<li><a href=\"#implementing-graphic-eq\">Implementing Graphic EQ</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#wrapping-up\">Wrapping Up</a></p>\n</li>\n</ul>","excerpt":"In this post, following the previous post, I’ll write about actually making audio effectors using the HTML5 Audio API. As already mentioned in the previous post, the Audio API has the basic concept of creating audio flow by connecting multiple nodes, and provides some abstracted nodes needed for making effectors by default, so it’s not that difficult.","html":"<p>In this post, following <a href=\"/2019/08/19/javascript-audio-effectors-gain/\">the previous post</a>, I’ll write about actually making audio effectors using the HTML5 Audio API.</p>\n<p>As already mentioned in the previous post, the Audio API has the basic concept of creating audio flow by connecting multiple nodes, and provides some abstracted nodes needed for making effectors by default, so it’s not that difficult.</p>\n<!-- more -->\n<p>We just need to know what role each effector we want to make plays, what principles it has, and what purposes it’s used for. Since there are extremely many types of effectors used in audio, we can’t make all effectors - I’m thinking of implementing about 5 basic, most commonly used effectors.</p>\n<p>The process of loading audio and creating a source node was already explained in the previous post, so I won’t explain it separately. This post starts explaining directly from implementing effectors. For all effectors, I’ll first briefly explain what that effector does and its principles, then dive straight into implementation without further ado.</p>\n<p>So let’s tear into them one by one.</p>\n<h2 id=\"compressor\" style=\"position:relative;\">Compressor<a href=\"#compressor\" aria-label=\"compressor permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 640px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/a32ed4690c9c17197a82088952b74f1e/b12f7/compressor.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 65.625%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAIAAAAmMtkJAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC9ElEQVR42iVSW0/TABjto4kPxhgjKHc3YGzCkLq262Bu3dbZbm032t3asg46WbuVbXTjMrmIQowiGkVkQwENIAkJCBp98tEfZtXk5OTLSb6ck5wD/Pz1O5mrZStr+sqrlY3t+u5Bfe/wPxr7R41/XN872tk/mlt9U1x8sf62UVl6ltFqrxuHwLvd4yvm4U5HeNAXc9NiIj3Jj6tiVhNlLZVRkxklNa4mpZwwoTrwlNXNEXF5CBttGfAKag34cHDaMejrx+JunJYfTiratCRPRrhkUswU9RmtXClVZrVy1RBBb9Tq5cmUCuGpNrsvV3kK7BycNXWDvSiNU6Mb62t7ezuf9j9+2Nk+PPz8/fv5t4uzi/PT4y8H689XQQ9l8/K0kEdI8aYFkctLQOPzSQsY7BthXVhQ17WVJ8sbr9bfb29t17febr4xjq2tTUOp6CW7i7zjTcmFqisktkKUrD8GGp+OW9HRPjfnQN1ZWcyr2SlNqepFfVqbntbm5/RqpThTLWcn0jbYb/Mm6MS4IxBvG2ZlfRmo7x/fginbfa4XxKyQAZ8N8Rlshfx3nIF+J27AjgYNWNCQ4WGCaQvKtLsiE0bsv89Q2OqOmuDwg4QayZS6oEgglotkyj0uluQLjFTq98SNqH3DozY3hxBjQ/54q5MZLy0C73ePmh2kZYTpAHElX1yo1dqHCKVQWlx4ZELoYrk6PzsP+mKJdK4XoSwoPVWaQYlEMxTOFBcAYwBNdqwXDXeBuP0+A2LR2xAx6IlCfs6oAMHjUCAG+lijbTNMmiDC4WWsKNlsx6TC3F/nARcx5GE67vohPO4kUp1g0GAPLXXDIZQU3LTUg4QsCGmGCDNEDod4myt03QxJ+Rng5eZHLEgNOAOXWgYxgiWj/OX2ex6CpTnxign2kjGKFW5YXBYYv2aGr3cjQnqiB8SAq2Y2rQInX3/4aSEiKlRykuFzUVGleSUq5rnMlLEHVipwkmYojKBQKSUi5iNCjh3LYxS/tPb6DwF8FVn0mZKkAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"compressor\" title=\"\" src=\"/static/a32ed4690c9c17197a82088952b74f1e/6af66/compressor.png\" srcset=\"/static/a32ed4690c9c17197a82088952b74f1e/69538/compressor.png 160w,\n/static/a32ed4690c9c17197a82088952b74f1e/72799/compressor.png 320w,\n/static/a32ed4690c9c17197a82088952b74f1e/6af66/compressor.png 640w,\n/static/a32ed4690c9c17197a82088952b74f1e/d9199/compressor.png 960w,\n/static/a32ed4690c9c17197a82088952b74f1e/b12f7/compressor.png 1020w\" sizes=\"(max-width: 640px) 100vw, 640px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n<p>A compressor is an effector that acts like a compressor, pressing down sound when it gets above a certain size to make it small again. Effectors that adjust sound size like this are called dynamic effectors.</p>\n<p>When using audio sources, many start mixing with a compressor applied by default to defend against clipping that occurs when audio signals suddenly get above a certain size. But one question might arise here:</p>\n<blockquote>\n<p>Wait, if you’re just preventing clipping, can’t you just reduce the gain?</p>\n</blockquote>\n<p>Right. Actually, reducing gain can defend against clipping to some degree. But since music generally has dynamics, recklessly lowering gain creates the sad situation where quiet sounds don’t get inputted at all.</p>\n<p>For example, imagine when you went to karaoke. Generally when singing ballads, you sing quietly with a calm feeling in the intro, then in the chorus the air pressure passing through vocal cords increases to hit high notes, making volume louder.</p>\n<p>If you approach by recklessly lowering gain to record, you inevitably must match gain to the loudest sound - the belting in the chorus - and then the calm intro parts will barely get inputted.</p>\n<center>\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 640px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/e94b2e7a65da940d05a7df7a850aac9d/80e3c/buzz.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 56.25%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAIEBf/EABYBAQEBAAAAAAAAAAAAAAAAAAIAAf/aAAwDAQACEAMQAAAByXSl0ows/8QAGxAAAQQDAAAAAAAAAAAAAAAAAgABESESMTP/2gAIAQEAAQUCiiDFPTyi5lv/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAYEQACAwAAAAAAAAAAAAAAAAAAAQIRIf/aAAgBAgEBPwFy0s//xAAZEAACAwEAAAAAAAAAAAAAAAAAEQECQRD/2gAIAQEABj8CeEaxCKc//8QAHBABAAICAwEAAAAAAAAAAAAAAQARIVExQZHB/9oACAEBAAE/IbOo1cewacGoFEZILtjU91/IlaqrP//aAAwDAQACAAMAAAAQyC//xAAWEQEBAQAAAAAAAAAAAAAAAAABEBH/2gAIAQMBAT8QAyf/xAAWEQEBAQAAAAAAAAAAAAAAAAAAASH/2gAIAQIBAT8QszL/xAAaEAEBAQADAQAAAAAAAAAAAAABEQAhMVFh/9oACAEBAAE/EB/qBR1cZ8PIvmjiSJ5ihS2q6vsxBwCr4zkTAq1d/9k='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"buzz\" title=\"\" src=\"/static/e94b2e7a65da940d05a7df7a850aac9d/c08c5/buzz.jpg\" srcset=\"/static/e94b2e7a65da940d05a7df7a850aac9d/0913d/buzz.jpg 160w,\n/static/e94b2e7a65da940d05a7df7a850aac9d/cb69c/buzz.jpg 320w,\n/static/e94b2e7a65da940d05a7df7a850aac9d/c08c5/buzz.jpg 640w,\n/static/e94b2e7a65da940d05a7df7a850aac9d/80e3c/buzz.jpg 720w\" sizes=\"(max-width: 640px) 100vw, 640px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n  <small>Varies slightly by singing technique, but this volume difference is bigger than you think</small>\n</center>\n<p>Here’s when you use a compressor to raise input gain to an appropriate level and compress sounds that are too loud, narrowing the gap between the intro’s quiet sounds and chorus’s loud sounds to match overall sound size.</p>\n<center>\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 640px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/d9f4ff329a6c4d949f007ffc87a38afd/fb4e7/audio-compression.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 38.75%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAIAAAB2/0i6AAAACXBIWXMAAA7DAAAOwwHHb6hkAAABH0lEQVR42l1Q25LDIAjN///ePna6bdIYN3c1mosILCbdfahzRoHDAaQAJEEi/gOdeLvIbL2vytd2HCgukg7pZuHbQUQqdmTBhhSAViAxVsB8p+yuxKqqx2fdKL0zr0Qm8RhpBAbiwjlrjTl2ofJZnB36Psbjcvc1TGUpxnC7wevFtSK5tWalGKCw1oUQtNZt207T5JyLMfZ9z0SiCd47Y3JRY9w0iYAi7NZBCBIsHo9Ho1T5LJumSUn+mzVz1x0nPTY6HnkKSGkYBjGkujGzZGbxNd7V53yzsTo3P/O0/f2eEC/KL75rW7s40QGy7K/wkFf1gQWwrtRUKqW7jdhHzHFZYcR+x68ZBPNBhTT6AJ7NF+9/2nY7F/mm6D3af+YvnCrO+RaF5TIAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"audio compression\" title=\"\" src=\"/static/d9f4ff329a6c4d949f007ffc87a38afd/6af66/audio-compression.png\" srcset=\"/static/d9f4ff329a6c4d949f007ffc87a38afd/69538/audio-compression.png 160w,\n/static/d9f4ff329a6c4d949f007ffc87a38afd/72799/audio-compression.png 320w,\n/static/d9f4ff329a6c4d949f007ffc87a38afd/6af66/audio-compression.png 640w,\n/static/d9f4ff329a6c4d949f007ffc87a38afd/d9199/audio-compression.png 960w,\n/static/d9f4ff329a6c4d949f007ffc87a38afd/21b4d/audio-compression.png 1280w,\n/static/d9f4ff329a6c4d949f007ffc87a38afd/fb4e7/audio-compression.png 1519w\" sizes=\"(max-width: 640px) 100vw, 640px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n  <small>Compress signals exceeding the threshold to make them fall below it</small>\n</center>\n<p>Also, I said compressors compress sound, but what compressing sound means might not be clear. A representative example is the clean “thud!”, “smack!” drum sounds we hear in typical music sources - that’s compressed sound. <small>(These punchy sounds are usually called damping.)</small></p>\n<p>Generally when recording drums, the characteristic reverb of the drum body resonating remains, but compressing this sound with a compressor can create the clean drum sound we typically hear.</p>\n<p>Beyond that, using compressors on bass can give a solid feeling, pull distant sounds closer or vice versa - just using compressors well can give sound tremendously many feelings. That’s why the teacher who taught me sound engineering emphasized the compressor’s importance a lot.</p>\n<p>Compressors are designed to let you set things like when to start compressing signals and at what speed to compress using several values. The <code class=\"language-text\">DynamicsCompressorNode</code> provided by HTML5 Audio API provides these same values, so we need to know what these values mean to use this node properly.</p>\n<h4 id=\"threshold\" style=\"position:relative;\">Threshold<a href=\"#threshold\" aria-label=\"threshold permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>Threshold means the threshold that determines from what size to compress sound. Uses dB (decibel) as the unit.</p>\n<h4 id=\"ratio\" style=\"position:relative;\">Ratio<a href=\"#ratio\" aria-label=\"ratio permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>Ratio is the value determining what proportion sound exceeding the threshold will decrease by. Since this value means the <code class=\"language-text\">input:output</code> ratio, it’s generally talked about as ratios like <code class=\"language-text\">2:1</code>, <code class=\"language-text\">5:1</code>.</p>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 292px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/4928391f2babd8b6166e59f0d6730a60/2e9f9/ratio.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 97.50000000000001%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAIAAAAC64paAAAACXBIWXMAAA51AAAOdQG5Y1EyAAAB0ElEQVR42pWT20/CMBjF+f+fNT56JWHGxOALMQa5BE3gSUPETKeBMW7bWMsu7MamZyuOuuCFL1nSNv3tnJ5+LXzsVjHKti3fDzAp7ISGYTgej02Ter6/GwxyMBjYts0MJLBpWf8hV6tVjkzgvf2DmarxS1tJWZYdx8ltK5wcn5YE4ReYafJkEIRYTOCr8hWhNI6in84JzcwtpXQ6nRqGYaf/KtRqdUoXcRzlLiTTXC6XGFuWhZyBBUGwWCyWrpvA5cuyQQjvGQ6jKILmcDh0Xdf3/dlsNplMIIuVfn+gaepa+ejwyCCUh2ESsKqq8/kcu5/SEkWx2+3K8pAQouuq43oJfHd3n9qOM7eAO51OvV5vNBrtdluSJCizwLKK0oySJoECDzebzVKpBAxR4ZA4oWmaEMQ2XdcpIZqq6sY8DyMh+IThnAir+KvYdAPz2SIktvXPtlvDfN/CJK/DV6a5gTVNG41Gbnp1LLC87PfZ6stXAvd6PeTpeR4w2EYqGDhcBTAWJg/4RRRbrdbmVeFDG2AHeogxCIyN2RS9cXN9XalUqtVbQRDOzy+KZ0VcwPb3DDJnW3p9fe49K4oivb0ryujh4RGxrmE+kqw9c4tb0/4EM4F9Se9NBhwAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"ratio\" title=\"\" src=\"/static/4928391f2babd8b6166e59f0d6730a60/2e9f9/ratio.png\" srcset=\"/static/4928391f2babd8b6166e59f0d6730a60/69538/ratio.png 160w,\n/static/4928391f2babd8b6166e59f0d6730a60/2e9f9/ratio.png 292w\" sizes=\"(max-width: 292px) 100vw, 292px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n<p>But the HTML5 Audio API property has slightly different units. The official docs say “dB value needed to change 1dB of output value” - just think assigning <code class=\"language-text\">12</code> to this property means compression ratio is <code class=\"language-text\">12:1</code>.</p>\n<p>Usually saying you applied compression moderately means about <code class=\"language-text\">4:1</code> ratio, so the default value of <code class=\"language-text\">12:1</code> for this property can be called quite hard compression.</p>\n<h4 id=\"attack\" style=\"position:relative;\">Attack<a href=\"#attack\" aria-label=\"attack permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>Attack is the value determining how fast to compress sound. Think of it as determining how fast to hit and press down values exceeding the threshold.</p>\n<p>Many people mistakenly think the attack time set here is “when attack starts,” but actually attack itself starts immediately when signal size exceeds threshold. The attack time we set is “time taken to reach the ratio set by Ratio.”</p>\n<p>The unit usually uses milliseconds, but Audio API uses seconds.</p>\n<h4 id=\"release\" style=\"position:relative;\">Release<a href=\"#release\" aria-label=\"release permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>While attack was the speed of pressing sound, release is the value determining how fast to release compressed sound. The release value aims for time to reach the standard volume of 10dB, not the sound’s original size.</p>\n<p>Like attack, release usually uses milliseconds as the unit but Audio API uses seconds.</p>\n<h4 id=\"knee\" style=\"position:relative;\">Knee<a href=\"#knee\" aria-label=\"knee permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>Knee is actually a feature absent in most hardware compressors but quite often seen in software compressors. This value determines how naturally the compressor will be applied.</p>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 640px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/aaa2aa40a71cd57ae933e06492b31b1f/68e9c/hard-soft-compression.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 45.62500000000001%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAIAAAC9o5sfAAAACXBIWXMAAA7zAAAO8wEcU5k6AAAA7ElEQVR42mWR2w6DIBBE+f9/1KiJd4zxUlFQ2yPbEhvnQWFmZ9gF5Zw7z/N9A9txHJdlYb3v+3EcT9UYw1r1fW+tFVaqt22DYcE21IlK0LquxoMaVVWVmIPGdhgGrTVM0zRBpUf4l4f2uMx5nrdtS1gcx0mSpGlaliU2DHVdo3ZdRwtRFMHD0CwMlstMn6Ry5uGBjTp4MXMy8xMxzzMMWyJQOUzhcR7vf8iQ8HimaXpeKscoAtDcDwTzhZQ4FszG5YkkgJQnUPzsDUxCqzQmZlS5fAET0TAFX7P0UBRF7pFl2f1tBGRJASpjBv4DXHMHixSVCw8AAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"hard soft compression\" title=\"\" src=\"/static/aaa2aa40a71cd57ae933e06492b31b1f/6af66/hard-soft-compression.png\" srcset=\"/static/aaa2aa40a71cd57ae933e06492b31b1f/69538/hard-soft-compression.png 160w,\n/static/aaa2aa40a71cd57ae933e06492b31b1f/72799/hard-soft-compression.png 320w,\n/static/aaa2aa40a71cd57ae933e06492b31b1f/6af66/hard-soft-compression.png 640w,\n/static/aaa2aa40a71cd57ae933e06492b31b1f/68e9c/hard-soft-compression.png 654w\" sizes=\"(max-width: 640px) 100vw, 640px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n<p>The bend degree in the graph above shows how gradually the compressor is applied. Compression applied quickly with a snap is called hard, while compression applied slowly is called soft.</p>\n<h3 id=\"implementing-compressor\" style=\"position:relative;\">Implementing Compressor<a href=\"#implementing-compressor\" aria-label=\"implementing compressor permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<p>Actually as mentioned above, since HTML5 Audio API inherently provides <code class=\"language-text\">DynamicsCompressorNode</code>, we don’t need to directly implement the sound compression algorithm. We just need to create the node and connect it.</p>\n<p>This time, instead of extracting audio buffers from user-uploaded audio files to create source nodes, I’ll proceed by extracting from <code class=\"language-text\">&lt;audio></code> tags to create source nodes. <small>(This makes code much simpler)</small> The source node created now will keep being used when implementing other effectors too.</p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-js line-numbers\"><code class=\"language-js\"><span class=\"token keyword\">const</span> audioContext <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token punctuation\">(</span>AudioContext <span class=\"token operator\">||</span> webkitAudioContext<span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> audioDOM <span class=\"token operator\">=</span> document<span class=\"token punctuation\">.</span><span class=\"token function\">getElementById</span><span class=\"token punctuation\">(</span><span class=\"token string\">'my-audio'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> sourceNode <span class=\"token operator\">=</span> audioContext<span class=\"token punctuation\">.</span><span class=\"token function\">createMediaElementSource</span><span class=\"token punctuation\">(</span>audioDOM<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">const</span> threshold <span class=\"token operator\">=</span> <span class=\"token operator\">-</span><span class=\"token number\">24</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> attack <span class=\"token operator\">=</span> <span class=\"token number\">0.003</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> release <span class=\"token operator\">=</span> <span class=\"token number\">0.25</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> ratio <span class=\"token operator\">=</span> <span class=\"token number\">12</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> knee <span class=\"token operator\">=</span> <span class=\"token number\">30</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">const</span> compressorNode <span class=\"token operator\">=</span> audioContext<span class=\"token punctuation\">.</span><span class=\"token function\">createDynamicsCompressor</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\ncompressorNode<span class=\"token punctuation\">.</span>threshold<span class=\"token punctuation\">.</span><span class=\"token function\">setValueAtTime</span><span class=\"token punctuation\">(</span>threshold<span class=\"token punctuation\">,</span> audioContext<span class=\"token punctuation\">.</span>currentTime<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\ncompressorNode<span class=\"token punctuation\">.</span>attack<span class=\"token punctuation\">.</span><span class=\"token function\">setValueAtTime</span><span class=\"token punctuation\">(</span>attack<span class=\"token punctuation\">,</span> audioContext<span class=\"token punctuation\">.</span>currentTime<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\ncompressorNode<span class=\"token punctuation\">.</span>release<span class=\"token punctuation\">.</span><span class=\"token function\">setValueAtTime</span><span class=\"token punctuation\">(</span>release<span class=\"token punctuation\">,</span> audioContext<span class=\"token punctuation\">.</span>currentTime<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\ncompressorNode<span class=\"token punctuation\">.</span>ratio<span class=\"token punctuation\">.</span><span class=\"token function\">setValueAtTime</span><span class=\"token punctuation\">(</span>ratio<span class=\"token punctuation\">,</span> audioContext<span class=\"token punctuation\">.</span>currentTime<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\ncompressorNode<span class=\"token punctuation\">.</span>knee<span class=\"token punctuation\">.</span><span class=\"token function\">setValueAtTime</span><span class=\"token punctuation\">(</span>knee<span class=\"token punctuation\">,</span> audioContext<span class=\"token punctuation\">.</span>currentTime<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">const</span> inputGainNode <span class=\"token operator\">=</span> audioContext<span class=\"token punctuation\">.</span><span class=\"token function\">createGain</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> outputGainNode <span class=\"token operator\">=</span> audioContext<span class=\"token punctuation\">.</span><span class=\"token function\">createGain</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\nsourceNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>inputGainNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\ninputGainNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>compressorNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\ncompressorNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>outputGainNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\noutputGainNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>audioContext<span class=\"token punctuation\">.</span>destination<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>I created audio source flow in the order source > gain > compressor > gain - this is actually personal preference. But since most compressors generally have both input gain and output gain, I implemented the same way.</p>\n<p>Playing the source node after this lets you hear compressed sound, but since non-sound-engineers struggle to feel subtle degrees of compression, I recommend changing the above values a bit extremely.</p>\n<h2 id=\"reverb\" style=\"position:relative;\">Reverb<a href=\"#reverb\" aria-label=\"reverb permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 640px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/168b553805699d40f75aa40227c69521/e3f06/reverb.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 53.75%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAMEAv/EABYBAQEBAAAAAAAAAAAAAAAAAAEAAv/aAAwDAQACEAMQAAABgNoc2Cyf/8QAHBAAAQQDAQAAAAAAAAAAAAAAAgABAxESITEy/9oACAEBAAEFAnjoY/ZdN3wDStf/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAXEAEAAwAAAAAAAAAAAAAAAAARECBB/9oACAEBAAY/AljKf//EABsQAQADAAMBAAAAAAAAAAAAAAEAESExUWGB/9oACAEBAAE/ITe9ryZx1KHMfCKQuVFayKuf/9oADAMBAAIAAwAAABCrz//EABYRAAMAAAAAAAAAAAAAAAAAABARIf/aAAgBAwEBPxBUf//EABYRAAMAAAAAAAAAAAAAAAAAABARIf/aAAgBAgEBPxBwf//EAB0QAQACAgIDAAAAAAAAAAAAAAEAESExUXFhgZH/2gAIAQEAAT8QW++xj9uVzEbtvEvD3EXuMJVpG0jSX4xGWaXon//Z'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"reverb\" title=\"\" src=\"/static/168b553805699d40f75aa40227c69521/c08c5/reverb.jpg\" srcset=\"/static/168b553805699d40f75aa40227c69521/0913d/reverb.jpg 160w,\n/static/168b553805699d40f75aa40227c69521/cb69c/reverb.jpg 320w,\n/static/168b553805699d40f75aa40227c69521/c08c5/reverb.jpg 640w,\n/static/168b553805699d40f75aa40227c69521/e3f06/reverb.jpg 643w\" sizes=\"(max-width: 640px) 100vw, 640px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n<p>Reverb is a spatial effector that gives sound a sense of space through resonance. What does giving a sense of space through resonance mean?</p>\n<p>Actually, we can roughly determine by hearing sound whether the current space is wide or narrow, whether this space is made of rough walls or smooth space like glass. The difference is so subtle that untrained people struggle to notice.</p>\n<p>How is this possible? Because of reverb from sound reflection. First, the principle of detecting space size by hearing sound is simple. After I shout “wah!” in a room, detect how long until the first reflected sound is heard.</p>\n<p>But since this first reflected sound returns to me at extremely fast millisecond speeds, it’s not about counting 1 second, 2 seconds - you just feel it. This reflected sound is called early reflection.</p>\n<p>But it doesn’t end there. Even after sound reflects once and reaches your ears, reflection will continue. These reverberations will bounce all around the space and reflect back to your ears.</p>\n<center>\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 640px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/3457634accb0a45c9bd6199020317de9/2bef9/reflection.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 46.25%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAIAAAC9o5sfAAAACXBIWXMAAA7zAAAO8wEcU5k6AAABwUlEQVR42l2RWW/TQBSF80/5JTyUB5SqvIDECxSJCipBW+jqSlWhJK5jgSjQdImdOIuz2HGc2p7FM7Znxh6ciE0cnbd7vivdeypMsNJC5kIWoshFIX5ZikIWeZFnPMtYxssYz1KWMc7+ZCpBFGCCBQKp7zEEFluWg5IBENxcX6ulNP1wb79eq6t11R7aUkqe8wU8Gg8xAjwhnGe54IXMly4iEFmd7slpXdlVdl5uP37y/O274zdbh4bZ/geejDCMshhSwRKRYUZKJyKllDqO22joTx+tvVdOjmqfVe3rp5o282d/YddzCYIJAYjROQmn8dwjQSySMAx73Z7RalVXqz8MY2j3e5blz2fF4jW/b8Y0TmmcxABxMsF+HzgTNLujIKExpQhhbBomAABiFEHABOe5YOV5+RKOE5IlJCUQcmqEg4Z7pbs3Gy3l2Ljtu8k0oCQV8n8VcllEBcaIIBDDIEhRc9apjb6dj5sPvjy793pj5UWvutl5+Kpzf91c3bTWj+x9zf144Z1fzZvdkKS0UvYRRQGEUYiBG3nDO2ccTL87t7rVvmz7F4anXboH2mjrw2DnbLCn2oo+3j41d8+MCKGfxXPjjIB+Rd8AAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"reflection\" title=\"\" src=\"/static/3457634accb0a45c9bd6199020317de9/6af66/reflection.png\" srcset=\"/static/3457634accb0a45c9bd6199020317de9/69538/reflection.png 160w,\n/static/3457634accb0a45c9bd6199020317de9/72799/reflection.png 320w,\n/static/3457634accb0a45c9bd6199020317de9/6af66/reflection.png 640w,\n/static/3457634accb0a45c9bd6199020317de9/d9199/reflection.png 960w,\n/static/3457634accb0a45c9bd6199020317de9/2bef9/reflection.png 1024w\" sizes=\"(max-width: 640px) 100vw, 640px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n  <small>Green lines are early reflections, blue lines bouncing everywhere are reverb</small>\n</center>\n<p>Characteristics like how long this reverb is heard, how clearly it’s heard determine the room’s material. Just hearing the explanation makes detecting space by hearing sound seem impossible, but the music you normally hear already contains spatial design applying this principle.</p>\n<p>Since reverb literally just needs to create reverb, some hardware reverbs use a method of putting materials like springs or metal plates inside equipment, playing audio to amplify reverb generated as materials vibrate. In other words, opening it up reveals just a spring or metal plate inside. <small>(Creating good sound with such simple structure is scarier…)</small></p>\n<p>However, implementing reverb in software is slightly different. Computers can’t generate natural analog signals like spring or metal plate vibrations, so they must implement through direct calculation. Software reverb divides into two main types: Convolution Reverb and Algorithm Reverb.</p>\n<p>But since implementing both reverbs in this post would make it too long, I’ll reluctantly focus on convolution reverb. <small>(Algorithm reverb alone is one post’s worth)</small></p>\n<h3 id=\"convolution-reverb\" style=\"position:relative;\">Convolution Reverb<a href=\"#convolution-reverb\" aria-label=\"convolution reverb permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<p>Convolution reverb is a method of recording actual space reverb then synthesizing the reverb audio source and original audio source to add actual space resonance to the original audio source.</p>\n<p>Briefly explaining a representative method of recording actual space reverb: play pure sine wave sounds continuously from low frequency to high frequency in the space you want to record, then record the resulting reverb.</p>\n<center>\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 640px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/139d22412a234cb2ac3a54c80f1ef282/46590/ir-recording.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 95.625%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAATABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAECAwT/xAAWAQEBAQAAAAAAAAAAAAAAAAAAAQL/2gAMAwEAAhADEAAAAa01zxrFI74LLA//xAAZEAEBAAMBAAAAAAAAAAAAAAABAAIQISL/2gAIAQEAAQUCnWXWYCDyA3//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/AR//xAAZEAABBQAAAAAAAAAAAAAAAAAAARAgIYH/2gAIAQEABj8CljWh/8QAHBAAAwABBQAAAAAAAAAAAAAAAAERQRAhMVFh/9oACAEBAAE/IX1qil28HIcixKBGGYJahs//2gAMAwEAAgADAAAAELwvPP/EABURAQEAAAAAAAAAAAAAAAAAAAEg/9oACAEDAQE/ECP/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/EB//xAAaEAEAAwEBAQAAAAAAAAAAAAABABEhMWFB/9oACAEBAAE/EA3fpLnCDS59gENtqLQhtsAPZm2lLnkO2loT5U1kCXU//9k='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"ir recording\" title=\"\" src=\"/static/139d22412a234cb2ac3a54c80f1ef282/c08c5/ir-recording.jpg\" srcset=\"/static/139d22412a234cb2ac3a54c80f1ef282/0913d/ir-recording.jpg 160w,\n/static/139d22412a234cb2ac3a54c80f1ef282/cb69c/ir-recording.jpg 320w,\n/static/139d22412a234cb2ac3a54c80f1ef282/c08c5/ir-recording.jpg 640w,\n/static/139d22412a234cb2ac3a54c80f1ef282/6a068/ir-recording.jpg 960w,\n/static/139d22412a234cb2ac3a54c80f1ef282/eea4a/ir-recording.jpg 1280w,\n/static/139d22412a234cb2ac3a54c80f1ef282/46590/ir-recording.jpg 2561w\" sizes=\"(max-width: 640px) 100vw, 640px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n  <small>Recording space IR - Source: http://www.alanjshan.com/impulse-response-capture/</small>\n</center>\n<p>Since this reverb signal is called Impulse Response (IR), convolution reverb is also called IR reverb. The recorded IR gets merged to the original source through an operation called convolution.</p>\n<p>If we start approaching this convolution concept mathematically, it gets headache-inducing and lengthens the post, so defining simply: just mixing different information together.</p>\n<p>Since many readers of this post are probably developers, using machine learning more familiar to us to explain convolution, we could use <a href=\"https://en.wikipedia.org/wiki/Convolutional_neural_network\" target=\"_blank\" rel=\"nofollow\">CNN (Convolutional Neural Network)</a> as an example learning algorithm.</p>\n<p>In CNN too, when sending first layer images to the second layer, it mixes matrix-implemented kernels <small>(or filters)</small> and images to generate feature maps then sends to the next layer. Here you can think the first layer image and kernel information mixed.</p>\n<center>\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 500px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/380a88c34eac31f9a0af42f7f4de4002/0b533/convolution.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 38.75%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAIAAAB2/0i6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAB1klEQVR42mN4/Pjx8+cvHj1+8uD+/Z8/f/7////7929Pnz598/r182fPHj58/OXrN6Dgv79/37179/btu8+fPn358uXTp89AQYZbt249evTkzt37ly5d+vnrF1Do16+ft2/fOnr06JEjRy9euvLt+4//IPDvzp07J06cvHrlyvUbNy5cvPz37z+Gvdt37t68+eCO7avmL1g0cwZI1b9/P3/8ePz4ycNHj758/fr371+g4O07d4KDg8PCQkNCgHSIn6/f/fv3GTbO6VvYVpgX5VcY5jy9o/7f//+PHj18//793z9/gOSvX79ev3nz6tWrM2fO8PDwcHJwcnFyiouK8nJzX716lcHDSKsh2ac81rMjw/fY5iU/f/4CevjDhw9///4B6gFqfvPmDdC3586d4+Hm4eXllZSQUFJU5OPlO3/+PIOVkpi7gXJuoG1Dovv+NXN//Pz54sWLt2/fAh0P1Pb792+gTqApFy9cEBYW5uXhFRQUlJOV4eHiAhrHUJ/ol+iib6vA56cnvnV+5w+wzcDwBGoD2g8k34PBqVOnGGCAhYWFjYUFpPn0vq0nd29cOWfS8hn9V0/shQTYfyQACTCgiXV1dU1NTS3NzS0tLRP6+1++fAkAiH1QfGGJI9IAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"convolution\" title=\"\" src=\"/static/380a88c34eac31f9a0af42f7f4de4002/0b533/convolution.png\" srcset=\"/static/380a88c34eac31f9a0af42f7f4de4002/69538/convolution.png 160w,\n/static/380a88c34eac31f9a0af42f7f4de4002/72799/convolution.png 320w,\n/static/380a88c34eac31f9a0af42f7f4de4002/0b533/convolution.png 500w\" sizes=\"(max-width: 500px) 100vw, 500px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n  <small>Mix original image and kernel to create new information - the feature map</small>\n</center>\n<p>Audio convolution reverb is the same. In this case, the information to mix just becomes the original source and IR.</p>\n<p>Since convolution is a process multiplying the frequency spectrums of two audio sources - original source and IR - frequencies overlapping between the two sources get emphasized while non-overlapping frequencies decay. When overlapping frequencies between original source and IR get emphasized like this, the original source takes on the IR’s sound quality characteristics - that’s exactly convolution reverb’s principle.</p>\n<center>\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 640px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/c055ddb7e8755ffb1cfef849a60b862f/5a190/signal-convolution.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 82.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAIAAABSJhvpAAAACXBIWXMAAFxGAABcRgEUlENBAAACIElEQVR42m1Ta2OjIBDM//9x109tEpPGmPSiBBVUQB4CN0guvfa6vkbYWWaXZRNj9N7jHVbLv3nkCZZleU5lT4wAbPBhjBlj5nmWUmptp2kSQjpnx3EEdM5xxvgw3+m43+/qur5er33fJ7LWGk5rVMT2jAXciI7FjAlZEBaQjJPq8uvlZbfbEUKEEIlsrc1o1RUB2zaBxYX6FtbRoFRY3IInJ4JwkJnIUAW1iYxHCcn0JCOmgo93GrVJgRoSVXL+NOj9lI14i3MTGbuy15RpOtiuZxcyfBDT3vvqzq93TRvWMEI0Y7NSab0NSsU5x/rWGG2sc54PfdPdftfX90NR7PdVeS72u/djsXt7O5/P2+3+dCqHYXjknGU/jWnONU9ph8V6G3+yh+xnztkWv0xmwu2Dx5tKimLgMov5gZy24S8ZHtIKaaXzbrKjcEI5NS+z9poZBmC8ccFBjsw5QzYSQOapcmrsBq6wD0rdu/7jRi5VtT1si1NxuVxO1el4Pr4Wr4fyMInpUbB/93ngkbHUMkr5rjPjyAc+KCnhM6sZJcWvmMRjn58FW8lBytB16Db0c6zrR4YIvjb1fzl/JUdAuTYJvCkFSKNNE581DWvXPVZGDBwM1Bz6+163rcUEAKU4IZZz23WWEEWpaVvTNBIOjGmRc0ajKqVQ89Qn1oTgQc6gLMu6vq29jbNl4QLO2ooWlET+tvtZfD60KJL61tNf7Q/9w9fqrhB2GAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"signal convolution\" title=\"\" src=\"/static/c055ddb7e8755ffb1cfef849a60b862f/6af66/signal-convolution.png\" srcset=\"/static/c055ddb7e8755ffb1cfef849a60b862f/69538/signal-convolution.png 160w,\n/static/c055ddb7e8755ffb1cfef849a60b862f/72799/signal-convolution.png 320w,\n/static/c055ddb7e8755ffb1cfef849a60b862f/6af66/signal-convolution.png 640w,\n/static/c055ddb7e8755ffb1cfef849a60b862f/5a190/signal-convolution.png 800w\" sizes=\"(max-width: 640px) 100vw, 640px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n  <small>Original signal and recorded IR signal after convolution operation</small>\n</center>\n<p>Actually since HTML5 Audio API provides <code class=\"language-text\">ConvolverNode</code> that performs convolution operations instead, you can make convolution reverb without knowing what convolution is.</p>\n<p>However, you need to at least know this effector has the principle of multiplying two signal information to create new signals to understand why I write such code, so I’m giving rough explanation.</p>\n<p>Anyway, having grasped convolution reverb’s rough principles, let’s make it now.</p>\n<h3 id=\"implementing-convolution-reverb\" style=\"position:relative;\">Implementing Convolution Reverb<a href=\"#implementing-convolution-reverb\" aria-label=\"implementing convolution reverb permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<p>First, HTML5 Audio API doesn’t provide something like <code class=\"language-text\">ReverbNode</code>. But as explained above, since it provides <code class=\"language-text\">ConvolverNode</code> supporting convolution operations, we just need to directly create the reverb source IR (Impulse Response).</p>\n<p>And since reverb is generally made to let you mix original source and reverb source according to ratio using <code class=\"language-text\">wet</code> and <code class=\"language-text\">dry</code> values, I’ll write code the same way.</p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-js line-numbers\"><code class=\"language-js\"><span class=\"token keyword\">const</span> mix <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> time <span class=\"token operator\">=</span> <span class=\"token number\">0.01</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> decay <span class=\"token operator\">=</span> <span class=\"token number\">0.01</span><span class=\"token punctuation\">;</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span></span></pre></div>\n<p>Explaining the 3 variables to use for reverb: <code class=\"language-text\">mix</code> means wet/dry ratio, <code class=\"language-text\">time</code> means reverb length, <code class=\"language-text\">decay</code> means reverb decrease speed. Now let’s directly generate IR using these values.</p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-js line-numbers\"><code class=\"language-js\"><span class=\"token keyword\">function</span> <span class=\"token function\">generateImpulseResponse</span> <span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n  <span class=\"token keyword\">const</span> sampleRate <span class=\"token operator\">=</span> audioContext<span class=\"token punctuation\">.</span>sampleRate<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">const</span> length <span class=\"token operator\">=</span> sampleRate <span class=\"token operator\">*</span> time<span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">const</span> impulse <span class=\"token operator\">=</span> audioContext<span class=\"token punctuation\">.</span><span class=\"token function\">createBuffer</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> length<span class=\"token punctuation\">,</span> sampleRate<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n  <span class=\"token keyword\">const</span> leftImpulse <span class=\"token operator\">=</span> impulse<span class=\"token punctuation\">.</span><span class=\"token function\">getChannelData</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">const</span> rightImpulse <span class=\"token operator\">=</span> impulse<span class=\"token punctuation\">.</span><span class=\"token function\">getChannelData</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n  <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">let</span> i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> length<span class=\"token punctuation\">;</span> i<span class=\"token operator\">++</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    leftImpulse<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>Math<span class=\"token punctuation\">.</span><span class=\"token function\">random</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token number\">2</span> <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> Math<span class=\"token punctuation\">.</span><span class=\"token function\">pow</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span> <span class=\"token operator\">-</span> i <span class=\"token operator\">/</span> length<span class=\"token punctuation\">,</span> decay<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    rightImpulse<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>Math<span class=\"token punctuation\">.</span><span class=\"token function\">random</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token number\">2</span> <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> Math<span class=\"token punctuation\">.</span><span class=\"token function\">pow</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span> <span class=\"token operator\">-</span> i <span class=\"token operator\">/</span> length<span class=\"token punctuation\">,</span> decay<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n\n  <span class=\"token keyword\">return</span> impulse<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>Looks complicated but tearing it apart reveals nothing much. <code class=\"language-text\">sampleRate</code> means the sample rate, i.e. sound quality, of the <code class=\"language-text\">IR</code> we want to generate, and <code class=\"language-text\">length</code> means <code class=\"language-text\">sampleRate * time</code>, i.e. buffer length for expressing reverb of <code class=\"language-text\">time</code> seconds.</p>\n<p>Then just create one buffer node, generate random values from <code class=\"language-text\">-1 ~ 1</code>, raise <code class=\"language-text\">1 - i / length</code> to the <code class=\"language-text\">decay</code> power and multiply by the just-generated random number. This makes values smaller as <code class=\"language-text\">i</code> increases, and smaller faster as <code class=\"language-text\">decay</code> increases. This expresses reverb decay. After that, pour these samples into the just-made buffer node and you’re done.</p>\n<p>Expressing the IR buffer generated like this as a waveform would have roughly the following shape:</p>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 640px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/2e23d03eabacbb33bc757852ef9e0434/212bf/decay.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 126.25%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAZABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAECBAX/xAAXAQEBAQEAAAAAAAAAAAAAAAABAgAD/9oADAMBAAIQAxAAAAHVfnbp52DMWgJB3//EABoQAAICAwAAAAAAAAAAAAAAAAEDEBECEiD/2gAIAQEAAQUCxlRZY2gChz//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/AR//xAAbEAACAQUAAAAAAAAAAAAAAAABEQAQMDFBof/aAAgBAQAGPwKpQYe5jtj/xAAdEAACAgEFAAAAAAAAAAAAAAAAAREhURAxcbHw/9oACAEBAAE/IWUV0e2GQ9ZmRFwHJEJKi8D1Z//aAAwDAQACAAMAAAAQAx+w/8QAFxEBAQEBAAAAAAAAAAAAAAAAARARYf/aAAgBAwEBPxBRm8n/xAAXEQEAAwAAAAAAAAAAAAAAAAAQAREh/9oACAECAQE/ENgo/8QAIBABAAICAgEFAAAAAAAAAAAAAQARITFBURBhcYGRsf/aAAgBAQABPxBBVvgG4C8p7iCqvPxMg4bUGeGWh6mWn5FYsNdxiWhu9svq+5a8lQ0eN5//2Q=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"decay\" title=\"\" src=\"/static/2e23d03eabacbb33bc757852ef9e0434/c08c5/decay.jpg\" srcset=\"/static/2e23d03eabacbb33bc757852ef9e0434/0913d/decay.jpg 160w,\n/static/2e23d03eabacbb33bc757852ef9e0434/cb69c/decay.jpg 320w,\n/static/2e23d03eabacbb33bc757852ef9e0434/c08c5/decay.jpg 640w,\n/static/2e23d03eabacbb33bc757852ef9e0434/212bf/decay.jpg 768w\" sizes=\"(max-width: 640px) 100vw, 640px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n<p>Ta-da, we simply generated IR like this. Now all that’s left is using <code class=\"language-text\">ConvolverNode</code> to synthesize the original source and this IR. Let’s first create the nodes needed to make the reverb effector’s audio flow.</p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-js line-numbers\"><code class=\"language-js\"><span class=\"token keyword\">const</span> inputNode <span class=\"token operator\">=</span> audioContext<span class=\"token punctuation\">.</span><span class=\"token function\">createGain</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> wetGainNode <span class=\"token operator\">=</span> audioContext<span class=\"token punctuation\">.</span><span class=\"token function\">createGain</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> dryGainNode <span class=\"token operator\">=</span> audioContext<span class=\"token punctuation\">.</span><span class=\"token function\">createGain</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> reverbNode <span class=\"token operator\">=</span> audioContext<span class=\"token punctuation\">.</span><span class=\"token function\">createConvolver</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> outputNode <span class=\"token operator\">=</span> audioContext<span class=\"token punctuation\">.</span><span class=\"token function\">createGain</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>As explained above, typical reverb effectors provide the function of mixing and outputting original source and reverb-applied source using wet/dry values. Here the dry source must connect directly to <code class=\"language-text\">outputNode</code> for output without going through the reverb effector, while the wet source must go through our made <code class=\"language-text\">reverbNode</code> once and output to <code class=\"language-text\">outputNode</code>.</p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-js line-numbers\"><code class=\"language-js\">sourceNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>inputNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">// Connect dry source node</span>\ninputNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>dryGainNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\ndryGainNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>outputNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\ndryGainNode<span class=\"token punctuation\">.</span>gain<span class=\"token punctuation\">.</span>value <span class=\"token operator\">=</span> <span class=\"token number\">1</span> <span class=\"token operator\">-</span> mix<span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">// Generate IR and input to Convolver's audio buffer</span>\nreverbNode<span class=\"token punctuation\">.</span>buffer <span class=\"token operator\">=</span> <span class=\"token function\">generateImpulseResponse</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">// Connect wet source node</span>\ninputNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>reverbNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nreverbNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>wetGainNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nwetGainNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>outputNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nwetGainNode<span class=\"token punctuation\">.</span>gain<span class=\"token punctuation\">.</span>value <span class=\"token operator\">=</span> mix<span class=\"token punctuation\">;</span>\n\noutputNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>audioContext<span class=\"token punctuation\">.</span>destination<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>We simply implemented convolution reverb like this. Actually what most affects convolution reverb quality is IR quality - since we made IR with roughly made sample audio, this reverb’s quality can’t be good. But playing and listening to the source node, you can amazingly hear that sound gained a sense of space.</p>\n<p>If there’s a chance, I’ll post algorithm reverb implementation next time. Algorithm reverb is reverb implemented 100% with algorithm only, unlike convolution reverb which records and uses actual space reverb. So it feels slightly artificial but can give a feeling different from convolution reverb, so sound engineers understand these two reverbs’ characteristics and use them appropriately.</p>\n<p>So for developers, algorithm reverb might actually be more understandable than convolution reverb, but unlike convolution reverb where you just need one <code class=\"language-text\">ConvolverNode</code> and a roughly made IR and the rest calculates automatically, algorithm reverb must truly be made from the ground up. So unfortunately I’ll post algorithm reverb next time.</p>\n<p>If you’re curious about algorithm reverb implementation, you can check <a href=\"https://github.com/evan-moon/simple-waveform-visualizer/blob/master/src/lib/effects/AlgorithmReverb.js\" target=\"_blank\" rel=\"nofollow\">my GitHub repository</a>.</p>\n<h2 id=\"delay\" style=\"position:relative;\">Delay<a href=\"#delay\" aria-label=\"delay permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 640px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/6c84397372fb970c1df011b86b5edfef/29177/delay.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 38.75%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAIABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAECBP/EABUBAQEAAAAAAAAAAAAAAAAAAAED/9oADAMBAAIQAxAAAAHPUhaAP//EABcQAAMBAAAAAAAAAAAAAAAAAAECERD/2gAIAQEAAQUCLYZf/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAGxAAAQQDAAAAAAAAAAAAAAAAAQAQETFBUaH/2gAIAQEABj8CEnivOm//xAAZEAEBAQADAAAAAAAAAAAAAAABEQAhMUH/2gAIAQEAAT8hSAWVcs4h9Y6zrf/aAAwDAQACAAMAAAAQdC//xAAWEQEBAQAAAAAAAAAAAAAAAAABABH/2gAIAQMBAT8QQ22//8QAFxEBAAMAAAAAAAAAAAAAAAAAAAERMf/aAAgBAgEBPxCMU//EABkQAAIDAQAAAAAAAAAAAAAAAAEhABFRMf/aAAgBAQABPxBUKIoScjwgC2cEcAZd5P/Z'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"delay\" title=\"\" src=\"/static/6c84397372fb970c1df011b86b5edfef/c08c5/delay.jpg\" srcset=\"/static/6c84397372fb970c1df011b86b5edfef/0913d/delay.jpg 160w,\n/static/6c84397372fb970c1df011b86b5edfef/cb69c/delay.jpg 320w,\n/static/6c84397372fb970c1df011b86b5edfef/c08c5/delay.jpg 640w,\n/static/6c84397372fb970c1df011b86b5edfef/29177/delay.jpg 749w\" sizes=\"(max-width: 640px) 100vw, 640px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n<p>Delay is the same spatial effector as reverb and can be thought similar since it repeats sound, but its principles and uses differ greatly.</p>\n<p>First, delay is simply an effect repeating sound, but reverb mimics complex reflected sounds within space, so using delay alone makes expressing natural spatial feeling like reverb difficult.</p>\n<p>The reverb effector we just made aims for realistic space expression so uses convolution or complex algorithms, but delay just needs to briefly delay the original source then play it again after <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>n</mi></mrow><annotation encoding=\"application/x-tex\">n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">n</span></span></span></span></span> seconds while gradually making sound quieter.</p>\n<center>\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 640px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/ecca82a37017f0e66ca8ff5f4c42f25d/1f083/reverb_vs_delay.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 66.25%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB3UlEQVR42p1SPW8aQRDlH7uMlCJKE6VwOnf5AenduCIgwUl2QUMTO0LojiMgA/e9s7v3/TxzYAFx7EheaW53b3fevvdmemmawliL1XKJ2f09qqrCO0Yjn7Zt/V5RFEiVAsoSTZJ2p5o0wjD6ZyYnIcsyJEnSzXVdnwOWDJQRgamh5QsyrGmgVLNf5wWSTB2pNA2GwyEGgwFGoxGWrOwloDA8A2yhDhgFO6DsOUNRled5Z88LhvIzjCIY9pK2W+RlgTg22O00cquZncaO98ZoVqIRM1trZX8MrXUjjwRB4PcEWV4jxYlbwsODi8UiwCawnKwRxOwnz0prpBy0B+jiFFA8jeN4D3g6RMJBxvuqbLllxOi6ruB5Lpv8B6vVCuv1mn1UkLZKuPqyfm4p8VFyTuIIKBdJE3JVwv21ZEkJt0zcAYkV8qCErA95/+vDkkHY6LTCj+8Zgq79Wj7Eq33oOA4mkwmm0ynG47Gsn1/ithFAZliZCt8+Z/jyFbi9FUmvG7bZbDCfz+G6LmazGRdxcQQUhkorlFTi8lOKDx+Bi4sWV1fA3R1YOt4EP5XMlvg9rihxuSnchjQepNT/aanft3RzY+j62pDjGHp8LIgL092TiKLo78g8z6t83//9BM+R5WNJLGHCAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"reverb vs delay\" title=\"\" src=\"/static/ecca82a37017f0e66ca8ff5f4c42f25d/6af66/reverb_vs_delay.png\" srcset=\"/static/ecca82a37017f0e66ca8ff5f4c42f25d/69538/reverb_vs_delay.png 160w,\n/static/ecca82a37017f0e66ca8ff5f4c42f25d/72799/reverb_vs_delay.png 320w,\n/static/ecca82a37017f0e66ca8ff5f4c42f25d/6af66/reverb_vs_delay.png 640w,\n/static/ecca82a37017f0e66ca8ff5f4c42f25d/1f083/reverb_vs_delay.png 660w\" sizes=\"(max-width: 640px) 100vw, 640px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n  <small>Difference between echo (delay) and reverb</small>\n</center>\n<p>Since delay has such simple principles, making it isn’t that difficult either.</p>\n<h3 id=\"implementing-delay\" style=\"position:relative;\">Implementing Delay<a href=\"#implementing-delay\" aria-label=\"implementing delay permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<p>HTML5’s Audio API provides <code class=\"language-text\">DelayNode</code> that delays and re-outputs input signals, so we can simply implement delay effectors using this node.</p>\n<p>However, simply using <code class=\"language-text\">DelayNode</code> alone can only cause one delay, so we’ll implement delay using one trick. Let’s first declare variables needed for delay.</p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-js line-numbers\"><code class=\"language-js\"><span class=\"token keyword\">const</span> mix <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> feedback <span class=\"token operator\">=</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> time <span class=\"token operator\">=</span> <span class=\"token number\">0.3</span><span class=\"token punctuation\">;</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span></span></pre></div>\n<p>Like reverb, most delay effectors also have the function of mixing and outputting original source and delayed source using wet/dry values, so I’ll implement the same way. And the <code class=\"language-text\">feedback</code> variable is the volume to decrease when the original source delays once, and the <code class=\"language-text\">time</code> variable means the echo interval. Having declared all variables to use for delay, now it’s time to make nodes.</p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-js line-numbers\"><code class=\"language-js\"><span class=\"token keyword\">const</span> inputNode <span class=\"token operator\">=</span> audioContext<span class=\"token punctuation\">.</span><span class=\"token function\">createGain</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> wetGainNode <span class=\"token operator\">=</span> audioContext<span class=\"token punctuation\">.</span><span class=\"token function\">createGain</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> dryGainNode <span class=\"token operator\">=</span> audioContext<span class=\"token punctuation\">.</span><span class=\"token function\">createGain</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> feedbackNode <span class=\"token operator\">=</span> audioContext<span class=\"token punctuation\">.</span><span class=\"token function\">createGain</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> delayNode <span class=\"token operator\">=</span> audioContext<span class=\"token punctuation\">.</span><span class=\"token function\">createDelay</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">const</span> outputNode <span class=\"token operator\">=</span> audioContext<span class=\"token punctuation\">.</span><span class=\"token function\">createGain</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p><code class=\"language-text\">wetGainNode</code> and <code class=\"language-text\">dryGainNode</code> are the same as reverb so let’s pass over them, and focus on the new nodes <code class=\"language-text\">feedbackNode</code> and <code class=\"language-text\">delayNode</code>. These two nodes are essentially the delay effector’s core. First, let’s look once more at what the delay effector does.</p>\n<blockquote>\n<p>Input -> Delay -> Decreased signal output -> Input -> Delay -> Decreased signal output…</p>\n</blockquote>\n<p>This is all the delay effector does. It repeatedly gradually delays signals and outputs decreased signals again. So I’ll implement this effector by connecting <code class=\"language-text\">delayNode</code> and <code class=\"language-text\">feedbackNode</code> to each other.</p>\n<center>\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 640px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/4d190f766bb560920bc66390824efb6c/29114/delay-nodes.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 56.25%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAABUklEQVR42mP4jxv8AgM8ChjwyH3+/Onjxw///v3DqXnHuXUZ00MqF6dXL8kEMjafWg0U3bTqZFrI9MrMJVVZS4GMzatPgQRPrsyaEVa1OAOoMnNGKFAjQ9f6KokEBvtqFccaNfF4hpYVpUB1tfkLxRkSbVWr7NSqRRni6wsXAwUblxbJpjA41mo41qjLJDF0ratiuPn0yorDc9cdX7z22MIVh+fceHIZqO78mTtLZx9cufDwygWHgQwgFygIlAIqgKsEasTi579///78+RNZBMgFCmLxMzA8/vz9A0d//4EUXXtwae2xJRtPLAeitUeXXHt4CWTov7/IKoEa0W3+8/c3kOxYXamVy+tap+1Wr6uVy9e2qhws9YdAVEFUbDy5LHGyT9H8+OJ58UDGhhNLwd75Q2w8f/76+dXrl2/fvfny5TPJiQQYQr9//wECrEEF0QwAoJQty6GnAz4AAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"delay nodes\" title=\"\" src=\"/static/4d190f766bb560920bc66390824efb6c/6af66/delay-nodes.png\" srcset=\"/static/4d190f766bb560920bc66390824efb6c/69538/delay-nodes.png 160w,\n/static/4d190f766bb560920bc66390824efb6c/72799/delay-nodes.png 320w,\n/static/4d190f766bb560920bc66390824efb6c/6af66/delay-nodes.png 640w,\n/static/4d190f766bb560920bc66390824efb6c/d9199/delay-nodes.png 960w,\n/static/4d190f766bb560920bc66390824efb6c/21b4d/delay-nodes.png 1280w,\n/static/4d190f766bb560920bc66390824efb6c/29114/delay-nodes.png 1920w\" sizes=\"(max-width: 640px) 100vw, 640px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n  <small>Such simple connection can implement delay</small>\n</center>\n<p>Connecting nodes like this makes audio signals inputted through <code class=\"language-text\">DelayNode</code> delay then output to <code class=\"language-text\">FeedbackNode</code> and <code class=\"language-text\">OutputNode</code>, and gain-decreased sound through <code class=\"language-text\">FeedbackNode</code> inputs to <code class=\"language-text\">DelayNode</code> again, delays, then outputs to <code class=\"language-text\">OutputNode</code>. Let’s connect nodes according to the diagram above.</p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-js line-numbers\"><code class=\"language-js\">sourceNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>inputNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">// Connect dry source node</span>\ninputNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>dryGainNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\ndryGainNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>outputNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\ndryGainNode<span class=\"token punctuation\">.</span>gain<span class=\"token punctuation\">.</span>value <span class=\"token operator\">=</span> <span class=\"token number\">1</span> <span class=\"token operator\">-</span> mix<span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">// Create delay loop</span>\ndelayNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>feedbackNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nfeedbackNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>delayNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">// Connect wet source node</span>\ninputNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>delayNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\ndelayNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>wetGainNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nwetGainNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>outputNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nwetGainNode<span class=\"token punctuation\">.</span>gain<span class=\"token punctuation\">.</span>value <span class=\"token operator\">=</span> mix<span class=\"token punctuation\">;</span>\n\noutputNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>audioContext<span class=\"token punctuation\">.</span>destination<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>Playing the source node now lets you hear sound with echo-like effects applied through the delay effector.</p>\n<h2 id=\"filter\" style=\"position:relative;\">Filter<a href=\"#filter\" aria-label=\"filter permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 640px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/39acf359c2bf68c771d7db4d300523e5/54bf4/filter.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 60%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAIAAADtbgqsAAAACXBIWXMAAAsTAAALEwEAmpwYAAACVUlEQVR42n2S62/SUBjG+4+ZuCkQNtrSy+k5vcM2NtyAkTHuhbbQFlqg5TLXdTpxLsY4Y2L84N/n4YOJiYnJkydPzsnvfd9zIWzHm8yXlr/2o5t5/LR6eH77+D358mvz8UcQP9mLu844rHVsqJfSQErKlZakvSBZuViioEwMJks3jDujWa0zcqPEixI3TGbxk7veWvO4562aZlBpmvLJOSqeiuoRg1QSqhma3z+kibYZ9N3I9NdeFLvR3SLeDidh35mbwXo4XTWtacOYdO2ZUqq8yjGvKS6dB4yo5QVIMjRh+ZvJ6l2UPG4/f4s/PX/4+jPePrrR7XTz3t/cm/6q74SGs9BOq3sH1P5hHpegocwIgGJIomG44/mtu7wzJsuBF5rBJozvMeytkuDmoefMO/Zs4EYYfpndwdgpQSme1+XjMlFtm23b74xn10P3eui1rKnpR71xYHiLcXgznEbdUWC4oX5WTeGZaR53ZqSC4YW4LoETBRVS2F0DhXQa6Tmg5qUiLe7yZd+uNHt49031auD4jf7oqmc1jBHucWU4RJaBKQrkWMAKgBMALwAkAiDwvMADCGiGZjiG4dhyvdV3ZuV6+6zWOrtsWcG6Ow6ILIsgAgUNaZqoqUjXUEEXsevqLhR0qahLsgQqjY7lL2stA+ui0cUHrHdtQhBhUYeKglRVxL7Tn/D3CgXEAw5lWQjUI1Qo0Wj31ISiyZIiyar8HyFJAvqJcnpBS3qahST+J0hNMwKRyQspit87yO8fMv8qRfIZIHI6IqHMasc5qGAYYxkWvqK43+hILPd7Ms/OAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"filter\" title=\"\" src=\"/static/39acf359c2bf68c771d7db4d300523e5/6af66/filter.png\" srcset=\"/static/39acf359c2bf68c771d7db4d300523e5/69538/filter.png 160w,\n/static/39acf359c2bf68c771d7db4d300523e5/72799/filter.png 320w,\n/static/39acf359c2bf68c771d7db4d300523e5/6af66/filter.png 640w,\n/static/39acf359c2bf68c771d7db4d300523e5/d9199/filter.png 960w,\n/static/39acf359c2bf68c771d7db4d300523e5/54bf4/filter.png 1007w\" sizes=\"(max-width: 640px) 100vw, 640px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n<p>Filter means a tool or concept for filtering something out. Since we already use the filter concept a lot normally, it’s not that hard to understand. And filters in audio effectors play the role of filtering out frequencies.</p>\n<p>Simply put, filters are effectors that can pick out only specific frequency ranges from audio frequency ranges and eliminate them. So filters are mainly used to filter out noise mixed in sound or filter out frequencies that are too low or too high creating useless resonance.</p>\n<p>Using these filter characteristics well lets you do quite interesting things - two representative examples are creating voices coming from telephones or sounds like music from clubs.</p>\n<p>First, voices coming from telephones can be created using a <code class=\"language-text\">Bandpass</code> filter that passes only specific band frequencies from all frequencies. Utilizing that telephones have limits in frequency bands they can transmit, cut out all frequencies except the 100 ~ 250Hz frequency band which is human voice range.</p>\n<p><div class=\"gatsby-resp-iframe-wrapper\" style=\"padding-bottom: 56.49999999999999%; position: relative; height: 0; overflow: hidden; margin-bottom: 1.0725rem\" > <div class=\"embedVideo-container\"> <iframe title=\"\" src=\"https://www.youtube.com/embed/JrbkbKt1iEM?rel=0\" class=\"embedVideo-iframe\" style=\"border:0; position: absolute; top: 0; left: 0; width: 100%; height: 100%; \" loading=\"eager\" allowfullscreen=\"\" sandbox=\"allow-same-origin allow-scripts allow-popups\"></iframe> </div> </div></p>\n<center>\n  <small>Around 5:00 in the above video, the \"Hey, kitty~\" part is the filtered voice</small>\n  <br />\n  <br />\n</center>\n<p>So using filters on human voice sources to cut out all frequencies except 100 ~ 250Hz band can create the voice we typically hear when talking on the phone.</p>\n<p>Music sounds from clubs are created with similar principles. Due to club characteristics, they’re usually located underground with narrow entrances. In such situations, when playing songs at clubs, since there’s almost no passage for sound to escape outside, when we hear songs playing at clubs from ground level, we hear very heavy “boom~ boom~” sounds.</p>\n<p>Due to club music characteristics, low sounds are often emphasized by strong drums and bass, and since low frequencies have higher object penetration than high frequencies, outside clubs we mainly hear low sounds that penetrated relatively more than high sounds. This wave characteristic isn’t limited to sound - other waves like light also have higher energy loss rates for high frequencies than low frequencies.</p>\n<p><div class=\"gatsby-resp-iframe-wrapper\" style=\"padding-bottom: 56.49999999999999%; position: relative; height: 0; overflow: hidden; margin-bottom: 1.0725rem\" > <div class=\"embedVideo-container\"> <iframe title=\"\" src=\"https://www.youtube.com/embed/qmhwHUHc1Hc?rel=0\" class=\"embedVideo-iframe\" style=\"border:0; position: absolute; top: 0; left: 0; width: 100%; height: 100%; \" loading=\"eager\" allowfullscreen=\"\" sandbox=\"allow-same-origin allow-scripts allow-popups\"></iframe> </div> </div></p>\n<center>\n  <small>From 6:27 a part appears changing to sound using lowpass filter passing only low frequencies</small>\n  <br />\n  <br />\n</center>\n<p>Sound engineers like this analyze how specific situation sounds are heard and use various effectors including filters to give that situation’s on-site feeling.</p>\n<p>Fortunately, HTML5 Audio API provides <code class=\"language-text\">BiquadFilterNode</code> that can make such filters, so we can avoid the sad situation of having to directly crack audio buffers to analyze frequencies. We just need to know what the values this node provides mean.</p>\n<p>Let’s look one by one at what properties <code class=\"language-text\">BiquadFilterNode</code> provides mean.</p>\n<h4 id=\"frequency\" style=\"position:relative;\">Frequency<a href=\"#frequency\" aria-label=\"frequency permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>Frequency is the value determining which frequency band to filter out. Uses Hz (hertz) as unit, and can assign values from 10Hz to half the audio’s sample rate. If audio source sample rate is 44,100Hz, this means you can assign up to 22,050.</p>\n<h4 id=\"q\" style=\"position:relative;\">Q<a href=\"#q\" aria-label=\"q permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p>Filtering signals fundamentally can’t be cut exactly like a knife. Since sound itself is an analog signal, it can’t be cut neatly square but inevitably filters with some boundary - here Q means how sensitively you can filter when filtering specific frequencies.</p>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 560px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/bd13c5d375c2729ffbcba3539fc82f14/b06ae/filter-q.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 75%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAIAAABr+ngCAAAACXBIWXMAAAsTAAALEwEAmpwYAAABjklEQVR42o1TXW/CMAzk//87HpDgAY0KRKHtSqt8OU7i7ppAB2ibdqLIdXK+szGrKSOlFDMQMPN6vd7tdtvtFt/7/X6z2Vyv10kkMKeMwlrhEZG+7621RGSUatuuadp2ftouo2maYRjarq+vTVUdzufzNxlwzpV67H3XdpIrTg9IhtFKjwMsoOgLGZqFbCyNn58hs5/Jc2siMd9ZLt/Jxpg72ZEdevfKXlyU4JuMIcEGWirv2jGNvfFRnoCjJXjucRVCOJ1OKJavTJpY9AByTO+2f1AGua7rmSwpzuQg+uZDciH9i1xV1TiOUAbBc4iqx5mikCRNf9tGKoSIHxnvllMMnNQADYhbH+8r9JB+Vy7HHkCJMAm75Aw6mJNRMHb0/qvtkoWydn5ePDISg3grMU6oATs+WGJCOzGiRxSgxXYhD7ebMzqSZU8x32Jn2JrgLJLeGnyM1tgxssaq8V0ZY2AOSqkccA4IysZapTXmgjzmCnEiX/yvln/VfQcfAXb4cPi4XOrj8Ygmy9Fs+wlfnjxs6L3IYCoAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"filter q\" title=\"\" src=\"/static/bd13c5d375c2729ffbcba3539fc82f14/b06ae/filter-q.png\" srcset=\"/static/bd13c5d375c2729ffbcba3539fc82f14/69538/filter-q.png 160w,\n/static/bd13c5d375c2729ffbcba3539fc82f14/72799/filter-q.png 320w,\n/static/bd13c5d375c2729ffbcba3539fc82f14/b06ae/filter-q.png 560w\" sizes=\"(max-width: 560px) 100vw, 560px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n<p>Q can be assigned values between 0.0001 ~ 1000, and higher Q values let you filter caught frequencies more sensitively. However, when filtering audio signals, if Q is too high it might sound unnatural and artificial rather than natural, so finding appropriate values is important.</p>\n<h4 id=\"type\" style=\"position:relative;\">Type<a href=\"#type\" aria-label=\"type permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h4>\n<p><code class=\"language-text\">BiquadFilterNode</code> can make various types of filters - they broadly divide into types that completely filter frequencies out, and types that can amplify or decrease specific frequencies.</p>\n<h5 id=\"types-that-filter-frequencies\" style=\"position:relative;\">Types that filter frequencies<a href=\"#types-that-filter-frequencies\" aria-label=\"types that filter frequencies permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h5>\n<ul>\n<li><code class=\"language-text\">lowpass (highcut)</code>: Filters out all frequencies higher than specified frequency.</li>\n<li><code class=\"language-text\">highpass (lowcut)</code>: Filters out all frequencies lower than specified frequency.</li>\n<li><code class=\"language-text\">bandpass</code>: Filters out all frequencies except specified frequency.</li>\n<li><code class=\"language-text\">notch</code>: Filters out specified frequency.</li>\n</ul>\n<h5 id=\"types-that-amplifydecrease-frequencies\" style=\"position:relative;\">Types that amplify/decrease frequencies<a href=\"#types-that-amplifydecrease-frequencies\" aria-label=\"types that amplifydecrease frequencies permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h5>\n<ul>\n<li><code class=\"language-text\">lowshelf</code>: Amplifies/decreases frequencies lower than specified frequency.</li>\n<li><code class=\"language-text\">highshelf</code>: Amplifies/decreases frequencies higher than specified frequency.</li>\n<li><code class=\"language-text\">peaking</code>: Amplifies/decreases specified frequency.</li>\n</ul>\n<p>Among these, types that amplify/decrease frequencies can also be used in EQ (Equalizer) discussed below. This time I plan to make filters simply filtering frequencies, so I’ll implement filters using only types that filter frequencies.</p>\n<p>I’ll implement a lowpass filter filtering all frequencies higher than specific frequency and a highpass filter filtering all frequencies lower than specific frequency. Let’s simply implement filters.</p>\n<h3 id=\"implementing-filter\" style=\"position:relative;\">Implementing Filter<a href=\"#implementing-filter\" aria-label=\"implementing filter permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<p>First use AudioContext object’s <code class=\"language-text\">createBiquadFilter</code> method to create <code class=\"language-text\">BiquadFilterNode</code>. Since my audio sample has 44,100Hz sample rate, I’ll set lowpass filter frequency to 1,000Hz and highpass filter frequency to 20,000Hz.</p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-js line-numbers\"><code class=\"language-js\"><span class=\"token keyword\">const</span> lowpassFilterNode <span class=\"token operator\">=</span> audioContext<span class=\"token punctuation\">.</span><span class=\"token function\">createBiquadFilter</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nlowpassFilterNode<span class=\"token punctuation\">.</span>type <span class=\"token operator\">=</span> <span class=\"token string\">'lowpass'</span><span class=\"token punctuation\">;</span>\nlowpassFilterNode<span class=\"token punctuation\">.</span>frequency<span class=\"token punctuation\">.</span><span class=\"token function\">setValueAtTime</span><span class=\"token punctuation\">(</span><span class=\"token number\">1000</span><span class=\"token punctuation\">,</span> audioContext<span class=\"token punctuation\">.</span>currentTime<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">const</span> highpassFilterNode <span class=\"token operator\">=</span> audioContext<span class=\"token punctuation\">.</span><span class=\"token function\">createBiquadFilter</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nhighpassFilterNode<span class=\"token punctuation\">.</span>type <span class=\"token operator\">=</span> <span class=\"token string\">'highpass'</span><span class=\"token punctuation\">;</span>\nhighpassFilterNode<span class=\"token punctuation\">.</span>frequency<span class=\"token punctuation\">.</span><span class=\"token function\">setValueAtTime</span><span class=\"token punctuation\">(</span><span class=\"token number\">20000</span><span class=\"token punctuation\">,</span> audioContext<span class=\"token punctuation\">.</span>currentTime<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>I didn’t separately set Q values, but that’s actually fine. <code class=\"language-text\">BiquadFilterNode</code>’s Q has default value 350 which isn’t too excessive or insufficient, so I’ll just use the default value. <small>(Also a bit lazy.)</small></p>\n<p>Now connecting the created filter nodes to the audio source lets you hear audio samples with frequencies below 1,000Hz and above 20,000Hz removed.</p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-js line-numbers\"><code class=\"language-js\">sourceNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>lowpassFilterNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nlowpassFilterNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>highpassFilterNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nhighpassFilterNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>audioContext<span class=\"token punctuation\">.</span>destination<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span></span></pre></div>\n<p>Those who’ve read this far probably started feeling, but actually HTML5 Audio API is so well made that developers barely need to touch anything. Before knowing <code class=\"language-text\">BiquadFilterNode</code> existed, I worried “wow how will I make this filter…?” but it was actually the one needing least worry. <small>(So it was slightly anticlimactic.)</small></p>\n<h2 id=\"eq\" style=\"position:relative;\">EQ<a href=\"#eq\" aria-label=\"eq permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 640px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/b972a654c602720bb3a9d335899a0d25/c1b63/parametric-eq.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 52.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAACmUlEQVR42j2RS28TVxiG5xdwB9meGXvseC5nbrbHM2PHcUKJg517CARBAiQBJBBBgqAoMgSQCpuy6YIFrVSpXVa0UretuuAnsOT3PJyZIBav3ve7nO92FOF6RK0WjWYT27ZxHBvLMtF1DU1Tczbrdcm6tI99xyyhlnIul/U8r2oYKK4bEIRNwnYfL4ikDnGEoKRqqJouWaeYab2c64yLqkpJy3wVtHJFDuKQDVarmyj6RIDhxNTdNEdVpFhBSk1y3Z9kwutiiATDS6g6CfVwGje8iAgk94bU/C6m08GwIkpVD8VsXsJN5yUWEMl8DiceYbeH1JuDnOO5TXrL9xGdRazWZWZ+2KY3s4WQb7zOUs5ONJCDJShWMsTtryH6V/Cn12nMbBDP3mBaFli+94qd17+x/8u/HP7+iQfv/mS0PWawvMfU3Dbe1CqBfOf1VnFls3rYRzlae8CLq3v8eH2fJ2uP2BjeYriww+LNZyzcPmT17hGjrYMcK7sv2bz/jqcP/+DN6/94Pv6H8eFfjA/+ZriyRy0r+HHrBR/vvOJg/TFpfx0/6za5gi3XsOJ57CSDXCldzG2RLLE02ufR7gfeHv3P+58+8+vPX1jbGKPZbZT3156wOb+N3pql1hpgRXPyTnOY0TGs9uUc2S0tiey+cW+DQBauNWeJpq7RvbiFK5sWJpoooRFyVqJiBlTtBiX5W067nQfL8tdVK6YoYvSkR6HWwoguobodJpxpbH9AodpAqCmFSkjJjlHKokvBjOWKI8qiw4miyfmqw8mSzSlNcEqVWpPacDlZtDhd8aXtcEbzOVcOZdzmQsnL807rAsVvd/FaCVF3hqDVwXZDiQaO15Ac0JCxdjpJM0q/+zJ2PJnnHWvbD7/ZIV8B/qNr5c4oeIoAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"parametric eq\" title=\"\" src=\"/static/b972a654c602720bb3a9d335899a0d25/6af66/parametric-eq.png\" srcset=\"/static/b972a654c602720bb3a9d335899a0d25/69538/parametric-eq.png 160w,\n/static/b972a654c602720bb3a9d335899a0d25/72799/parametric-eq.png 320w,\n/static/b972a654c602720bb3a9d335899a0d25/6af66/parametric-eq.png 640w,\n/static/b972a654c602720bb3a9d335899a0d25/d9199/parametric-eq.png 960w,\n/static/b972a654c602720bb3a9d335899a0d25/c1b63/parametric-eq.png 1200w\" sizes=\"(max-width: 640px) 100vw, 640px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n<p>Equalizer (EQ) is an effector used for a kind of frequency equalization work (Frequency Equalizing) as the name suggests.</p>\n<p>EQ is a basic effector laid down with compressors when mixing audio, mainly used to eliminate useless sounds from original sources and harmonize with other sounds. Since EQ is ultimately an effector controlling frequencies, it’s implemented using filters - since we’ve already made filters once, we can easily whip up EQ.</p>\n<p>EQ broadly divides into two types: parametric equalizer and graphic equalizer - I plan to implement graphic equalizer among these. By the way, the image at top is parametric EQ, but I included it because the image looked cooler. For reference, graphic EQ looks like this:</p>\n<center>\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 640px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/810256ab252fd73a1c3030c32279669f/49e4f/graphic-eq.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 71.875%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAOABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAQD/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAclaJliP/8QAHBAAAgEFAQAAAAAAAAAAAAAAAAEDAgQRExQh/9oACAEBAAEFAud5cDFbs2+uYVZ//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAGxAAAQQDAAAAAAAAAAAAAAAAAAEQMTJBkaH/2gAIAQEABj8Csmi/CTJKt//EABwQAAICAgMAAAAAAAAAAAAAAAABESFRgTGR8f/aAAgBAQABPyHAtjCdh1cXopBOh4Apq5Z//9oADAMBAAIAAwAAABAYz//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oACAEDAQE/EEf/xAAVEQEBAAAAAAAAAAAAAAAAAAAAAf/aAAgBAgEBPxBY/8QAGhABAQEBAQEBAAAAAAAAAAAAAREAITFhsf/aAAgBAQABPxDoHs88NxX40NWnd6o/dakCgQhMggdStGdoYZWb/9k='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"graphic eq\" title=\"\" src=\"/static/810256ab252fd73a1c3030c32279669f/c08c5/graphic-eq.jpg\" srcset=\"/static/810256ab252fd73a1c3030c32279669f/0913d/graphic-eq.jpg 160w,\n/static/810256ab252fd73a1c3030c32279669f/cb69c/graphic-eq.jpg 320w,\n/static/810256ab252fd73a1c3030c32279669f/c08c5/graphic-eq.jpg 640w,\n/static/810256ab252fd73a1c3030c32279669f/49e4f/graphic-eq.jpg 836w\" sizes=\"(max-width: 640px) 100vw, 640px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n  <small>Graphic EQ visual exuding deep analog nostalgia</small>\n</center>\n<p>Both EQs have pros and cons - first, graphic EQ’s advantage is having more controllable frequency bands than parametric EQ and having an intuitive interface. You might say seeing the parametric EQ image attached at this paragraph’s top “huh? Parametric looks quite intuitive too?” - but originally hardware parametric EQ looked like this:</p>\n<center>\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 640px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/351a26bf4458838f2afdbc6e4cb82da6/07f3a/hardware-parametric-eq.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 20.625%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAEABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAMC/8QAFgEBAQEAAAAAAAAAAAAAAAAABAAC/9oADAMBAAIQAxAAAAHExB6DV//EABgQAQADAQAAAAAAAAAAAAAAAAIAEiEi/9oACAEBAAEFAkeqwnP/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAWEAADAAAAAAAAAAAAAAAAAAAAATH/2gAIAQEABj8CrKys/8QAGRAAAgMBAAAAAAAAAAAAAAAAAAERUcHw/9oACAEBAAE/IUyts7sl1n//2gAMAwEAAgADAAAAEHwv/8QAFhEAAwAAAAAAAAAAAAAAAAAAARAx/9oACAEDAQE/EBF//8QAFREBAQAAAAAAAAAAAAAAAAAAEEH/2gAIAQIBAT8Qp//EABoQAAICAwAAAAAAAAAAAAAAAAABETEhQWH/2gAIAQEAAT8QexUtXY1UBmG79H//2Q=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"hardware parametric eq\" title=\"\" src=\"/static/351a26bf4458838f2afdbc6e4cb82da6/c08c5/hardware-parametric-eq.jpg\" srcset=\"/static/351a26bf4458838f2afdbc6e4cb82da6/0913d/hardware-parametric-eq.jpg 160w,\n/static/351a26bf4458838f2afdbc6e4cb82da6/cb69c/hardware-parametric-eq.jpg 320w,\n/static/351a26bf4458838f2afdbc6e4cb82da6/c08c5/hardware-parametric-eq.jpg 640w,\n/static/351a26bf4458838f2afdbc6e4cb82da6/07f3a/hardware-parametric-eq.jpg 740w\" sizes=\"(max-width: 640px) 100vw, 640px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n  <small>Black things are knobs. White things are numbers.</small>\n  <br>\n</center>\n<p>So graphic EQ is mainly used in places needing quick response like concert halls, and senior sound engineers with much experience have the scary skill of immediately catching the frequency when howling <small>(sharp “screee-” sound sometimes in karaoke)</small> occurs at concert halls and killing it with graphic EQ.</p>\n<p>Graphic EQ’s disadvantages are that controllable frequency bands are fixed and fine frequency adjustment is difficult. Conversely, parametric EQ unlike graphic EQ can even set all controllable frequency bands.</p>\n<p>However, simultaneously controllable frequency count is greatly lacking compared to graphic EQ. While typical parametric EQ can control 3-5 frequency bands, graphic EQ has experts with over 40 simultaneously controllable frequencies.</p>\n<p>I think hardware parametric EQ’s maximum disadvantage is having a non-intuitive interface - this disadvantage is an area coverable with UI when implementing in software, and since most recording studios have situations where you can keep listening and equalizing rather than immediate response, many software EQs are implemented as parametric EQ with high freedom in frequency band control.</p>\n<p>But in situations like the demo I’m making where I’m simply implementing, it’ll obviously be implemented with UI similar to hardware parametric EQ above, so I chose graphic EQ which is relatively easier to make UI for. <small>(If you don’t understand this well, check the parametric EQ attached at the EQ chapter’s very top)</small></p>\n<p>As mentioned once above, since EQ is implemented using filters, it’s not that complex. Let’s simply whip it up now.</p>\n<h3 id=\"implementing-graphic-eq\" style=\"position:relative;\">Implementing Graphic EQ<a href=\"#implementing-graphic-eq\" aria-label=\"implementing graphic eq permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<p>If you saw the graphic EQ image above, you know this guy is equipment with fixed controllable frequency band counts. So I’ll also declare one array containing controllable frequencies and iterate this array while generating filters.</p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-js line-numbers\"><code class=\"language-js\"><span class=\"token keyword\">const</span> frequencies <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\n  <span class=\"token number\">25</span><span class=\"token punctuation\">,</span> <span class=\"token number\">31</span><span class=\"token punctuation\">,</span> <span class=\"token number\">40</span><span class=\"token punctuation\">,</span> <span class=\"token number\">50</span><span class=\"token punctuation\">,</span> <span class=\"token number\">63</span><span class=\"token punctuation\">,</span> <span class=\"token number\">80</span><span class=\"token punctuation\">,</span> <span class=\"token number\">100</span><span class=\"token punctuation\">,</span> <span class=\"token number\">125</span><span class=\"token punctuation\">,</span> <span class=\"token number\">160</span><span class=\"token punctuation\">,</span> <span class=\"token number\">200</span><span class=\"token punctuation\">,</span>\n  <span class=\"token number\">250</span><span class=\"token punctuation\">,</span> <span class=\"token number\">315</span><span class=\"token punctuation\">,</span> <span class=\"token number\">400</span><span class=\"token punctuation\">,</span> <span class=\"token number\">500</span><span class=\"token punctuation\">,</span> <span class=\"token number\">630</span><span class=\"token punctuation\">,</span> <span class=\"token number\">800</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1000</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1250</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1600</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2000</span><span class=\"token punctuation\">,</span>\n  <span class=\"token number\">2500</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3150</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4000</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5000</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6300</span><span class=\"token punctuation\">,</span> <span class=\"token number\">8000</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10000</span><span class=\"token punctuation\">,</span> <span class=\"token number\">12500</span><span class=\"token punctuation\">,</span> <span class=\"token number\">16000</span><span class=\"token punctuation\">,</span> <span class=\"token number\">20000</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>There’s a point to note here. Since EQ uses multiple filters, you must chain-connect each filter to each other. If filter gain is even slightly higher than 1, sound amplifies a bit each time passing through filters, and by the time it reaches your ears it becomes extremely loud sound that could permanently separate your eardrums.</p>\n<blockquote>\n<p>🚨 <strong>Therefore you must set filters’ gain to 0 or below.</strong></p>\n</blockquote>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-js line-numbers\"><code class=\"language-js\"><span class=\"token keyword\">const</span> inputNode <span class=\"token operator\">=</span> audioContext<span class=\"token punctuation\">.</span><span class=\"token function\">createGain</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nsourceNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>inputNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">const</span> filters <span class=\"token operator\">=</span> frequencies<span class=\"token punctuation\">.</span><span class=\"token function\">map</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token parameter\">frequency<span class=\"token punctuation\">,</span> index<span class=\"token punctuation\">,</span> array</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=></span> <span class=\"token punctuation\">{</span>\n  <span class=\"token keyword\">const</span> filterNode <span class=\"token operator\">=</span> audioContext<span class=\"token punctuation\">.</span><span class=\"token function\">createBiquadFilter</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  filterNode<span class=\"token punctuation\">.</span>gain<span class=\"token punctuation\">.</span>value <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n  filterNode<span class=\"token punctuation\">.</span>frequency<span class=\"token punctuation\">.</span><span class=\"token function\">setValueAtTime</span><span class=\"token punctuation\">(</span>frequency<span class=\"token punctuation\">,</span> audioContext<span class=\"token punctuation\">.</span>currentTime<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>index <span class=\"token operator\">===</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    filterNode<span class=\"token punctuation\">.</span>type <span class=\"token operator\">=</span> <span class=\"token string\">'lowshelf'</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n  <span class=\"token keyword\">else</span> <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>index <span class=\"token operator\">===</span> array<span class=\"token punctuation\">.</span>length <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    filterNode<span class=\"token punctuation\">.</span>type <span class=\"token operator\">=</span> <span class=\"token string\">'highshelf'</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n  <span class=\"token keyword\">else</span> <span class=\"token punctuation\">{</span>\n    filterNode<span class=\"token punctuation\">.</span>type <span class=\"token operator\">=</span> <span class=\"token string\">'peaking'</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n  <span class=\"token keyword\">return</span> filterNode<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\nfilters<span class=\"token punctuation\">.</span><span class=\"token function\">reduce</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token parameter\">prev<span class=\"token punctuation\">,</span> current</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=></span> <span class=\"token punctuation\">{</span>\n  prev<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>current<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">return</span> current<span class=\"token punctuation\">;</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span> inputNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">const</span> outputNode <span class=\"token operator\">=</span> audioContext<span class=\"token punctuation\">.</span><span class=\"token function\">createGain</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nfilters<span class=\"token punctuation\">[</span>filters<span class=\"token punctuation\">.</span>length <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>outputNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\noutputNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>audioContext<span class=\"token punctuation\">.</span>destination<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>Looking at the <code class=\"language-text\">if</code> statement inside <code class=\"language-text\">map</code> method shows only the first and last filters getting different types - this is to cover all frequencies lower than first filter frequency and higher than last filter frequency using shelf type filters. <small>(If you don’t remember filter types well, go back and see the Filter part)</small></p>\n<p>Then chained all generated filters through <code class=\"language-text\">reduce</code> method and connected to <code class=\"language-text\">outputNode</code> too. Playing <code class=\"language-text\">sourceNode</code> after writing this far shows no changes.</p>\n<p>Naturally since all filters’ gain is <code class=\"language-text\">0</code> there are no changes. Assigning random numbers between <code class=\"language-text\">-1 ~ 1</code> to these filters’ values lets you hear sound change slightly. I personally recommend making it controllable by connecting with <code class=\"language-text\">input[type=\"range\"]</code> elements to control filters’ gain and directly trying various things.</p>\n<p>Also, since the lowest and highest frequency filters are set to shelf type, lowering these filters’ gain can also produce effects like lowpass or highpass filters.</p>\n<h2 id=\"wrapping-up\" style=\"position:relative;\">Wrapping Up<a href=\"#wrapping-up\" aria-label=\"wrapping up permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<p>So here we made commonly used effectors - compressor, reverb, delay, filter, EQ. Actually there are various other interesting effectors besides these 5, but I’ll stop here due to massive volume control failure.</p>\n<p>As mentioned once when making filters, since HTML5 Audio API provides extremely high-level abstracted nodes, there’s actually not much for developers to directly implement. This also means detailed-level implementation is difficult, but since I’m not starting some audio effector company, it seems sufficient for making things just for fun.</p>\n<p>Making various effectors like this brought back memories from when I worked as a sound engineer, and I had new things to learn about effectors too, so I had extremely fun working. Besides effectors written in the post, I plan to keep implementing various effectors, so interested people can look around <a href=\"https://github.com/evan-moon/simple-waveform-visualizer\" target=\"_blank\" rel=\"nofollow\">my GitHub</a> and send PRs. <small>(Good things double when shared.)</small></p>\n<p>That’s all for this post on making audio effectors with JavaScript - creating your own sound.</p>","fields":{"slug":"20190821-javascript-audio-effectors-practice-en","path":"/2019/08/21/javascript-audio-effectors-practice/en/","lang":"en"},"frontmatter":{"title":"[Making JavaScript Audio Effectors] Creating Your Own Sound with Audio Effectors","subTitle":"Like Logic Pro, Pro Tools? Implementing audio effects on the web","date":"Aug 21, 2019","categories":["Programming","Audio"],"tags":["JavaScript","JavaScript","Audio","Audio Effectors","JavaScript Audio API","Logic Pro X","Logic Pro","Protools","Pro Tools","Cubase","Cubase","Audio Plugin","Compressor","Delay","Reverb","EQ"],"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/026a9fe9c894f201ec1e45217221447c/3a812/thumbnail.jpg","srcSet":"/static/026a9fe9c894f201ec1e45217221447c/3a812/thumbnail.jpg 320w,\n/static/026a9fe9c894f201ec1e45217221447c/4b287/thumbnail.jpg 750w","sizes":"(min-width: 320px) 320px, 100vw"},"sources":[{"srcSet":"/static/026a9fe9c894f201ec1e45217221447c/fc5c5/thumbnail.webp 320w,\n/static/026a9fe9c894f201ec1e45217221447c/e9225/thumbnail.webp 750w","type":"image/webp","sizes":"(min-width: 320px) 320px, 100vw"}]},"width":320,"height":320}}},"jumbotron":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","images":{"fallback":{"src":"/static/026a9fe9c894f201ec1e45217221447c/2d839/thumbnail.jpg","srcSet":"/static/026a9fe9c894f201ec1e45217221447c/2d839/thumbnail.jpg 750w","sizes":"100vw"},"sources":[{"srcSet":"/static/026a9fe9c894f201ec1e45217221447c/b384d/thumbnail.webp 750w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5}}}}}},{"node":{"id":"8b0cac9f-d507-5cff-b551-9399ef553f53","tableOfContents":"<ul>\n<li>\n<p><a href=\"#audio-signals-flow\">Audio Signals Flow</a></p>\n</li>\n<li>\n<p><a href=\"#controlling-audio-volume\">Controlling Audio Volume</a></p>\n<ul>\n<li><a href=\"#what-is-gain\">What is Gain?</a></li>\n<li><a href=\"#lets-control-volume-using-gain-node\">Let’s Control Volume Using Gain Node</a></li>\n</ul>\n</li>\n</ul>","excerpt":"In this post, following the audio waveform drawing from How Do Computers Hear Sound?, I want to explain the process of creating effectors that can apply various effects to audio. HTML5’s Audio API provides various nodes that can apply effects to audio, and most effectors can be implemented using just these nodes - the API is that well-designed.","html":"<p>In this post, following the audio waveform drawing from <a href=\"/2019/07/10/javascript-audio-waveform/\">How Do Computers Hear Sound?</a>, I want to explain the process of creating effectors that can apply various effects to audio. HTML5’s Audio API provides various nodes that can apply effects to audio, and most effectors can be implemented using just these nodes - the API is that well-designed.</p>\n<!-- more -->\n<p>Also, this post will be written in two parts. This post will cover the overview of HTML5 Audio API and how to use <code class=\"language-text\">GainNode</code> which can control audio volume, and the next post will explain more complex audio effectors and their production process.</p>\n<p>Since I already explained basic theory about audio in the last post, this time I’ll focus not on basic theory but on methods of how audio is actually controlled and effects are applied in recording studios.</p>\n<h2 id=\"audio-signals-flow\" style=\"position:relative;\">Audio Signals Flow<a href=\"#audio-signals-flow\" aria-label=\"audio signals flow permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<p>In typical recording studios, we record audio through microphones or load already recorded audio into DAWs (Digital Audio Workstations) like <a href=\"https://www.apple.com/kr/logic-pro/\" target=\"_blank\" rel=\"nofollow\">Logic Pro</a> or <a href=\"https://www.steinberg.net/cubase/\" target=\"_blank\" rel=\"nofollow\">Cubase</a>. This audio we first receive is called the source.</p>\n<p>This source passes through various effectors that can give audio a special feeling - amps, compressors, equalizers, etc. - and finally gets output through speakers or headphones. Understanding this flow makes it easy to grasp the concept of nodes provided by HTML5’s Audio API. First, to help understanding, let me use as an example the system I used when I worked as a sound engineer.</p>\n<center>\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 640px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/aff4396076e86089c7d109c73767fe80/768c6/mixer.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 75%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAMEAv/EABUBAQEAAAAAAAAAAAAAAAAAAAIB/9oADAMBAAIQAxAAAAGVitK2kAH/AP/EABoQAAIDAQEAAAAAAAAAAAAAAAECAAMSEyL/2gAIAQEAAQUCGrIiuFR/KWZhtM6Gf//EABURAQEAAAAAAAAAAAAAAAAAAAAS/9oACAEDAQE/AVP/xAAWEQEBAQAAAAAAAAAAAAAAAAAAEyH/2gAIAQIBAT8B1N//xAAbEAABBAMAAAAAAAAAAAAAAAAAAREhMQIQQf/aAAgBAQAGPwJk4ZQTZTlNr//EABwQAQACAgMBAAAAAAAAAAAAAAEAESFxMUFhsf/aAAgBAQABPyEd3SUajEYJc0iO6bRzgeCLc/J//9oADAMBAAIAAwAAABAvL//EABcRAQEBAQAAAAAAAAAAAAAAAAEAEUH/2gAIAQMBAT8QMhnL/8QAGBEBAAMBAAAAAAAAAAAAAAAAAQARITH/2gAIAQIBAT8QTgMjZuf/xAAcEAEBAQACAwEAAAAAAAAAAAABEQAhQWHB4fD/2gAIAQEAAT8Qjk3IGDawGHY8e8DoLRjvO4ySfGToNE/POfqr5z//2Q=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"mixer\" title=\"\" src=\"/static/aff4396076e86089c7d109c73767fe80/c08c5/mixer.jpg\" srcset=\"/static/aff4396076e86089c7d109c73767fe80/0913d/mixer.jpg 160w,\n/static/aff4396076e86089c7d109c73767fe80/cb69c/mixer.jpg 320w,\n/static/aff4396076e86089c7d109c73767fe80/c08c5/mixer.jpg 640w,\n/static/aff4396076e86089c7d109c73767fe80/6a068/mixer.jpg 960w,\n/static/aff4396076e86089c7d109c73767fe80/eea4a/mixer.jpg 1280w,\n/static/aff4396076e86089c7d109c73767fe80/768c6/mixer.jpg 3264w\" sizes=\"(max-width: 640px) 100vw, 640px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n  <small>Equipment I used back in the day</small>\n</center>\n<p>The large equipment in the center of the photo is probably equipment you’ve seen a few times on TV. This equipment is a mixing console that plays a kind of control tower role, capable of handling volume, panning, and equalizing of audio sources divided into multiple channels.</p>\n<p>And the things to the right of the mixing console are effectors that can apply effects to audio. Usually you fill both sides of the mixing console and use them, but that photo is when the recording studio setup wasn’t finished yet so only a few pieces of equipment are in. And though not shown in the photo, there’s a separate shelf called console rack that’s also filled with effectors.</p>\n<p>And looking at the top of the effectors, you can see red wires plugged in - that equipment is called a patch table that can control the flow of audio.</p>\n<p>Usually sound engineers use multiple types of equipment even for effectors that serve the same role, because even effectors serving the same role can sound slightly different depending on the equipment.</p>\n<p>In other words, even using the same reverb, depending on what feeling the final sound you want to create has, you might use reverb A or reverb B. So the unique algorithms that create this sound quality are manufacturing companies’ trade secrets.</p>\n<p>But pulling out cables plugged into equipment one by one every time you want to use a different effector and reconnecting them to other equipment is inefficient, and constantly pulling out and plugging in cables can damage equipment, so you connect lines from all equipment to that patch table and use it. Plus, since cables are mostly located at the back of equipment, you have to push that mixing console forward a bit to see, and just looking at it, doesn’t that large equipment look too heavy to keep pushing and pulling? Your back goes out.</p>\n<center>\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 640px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/97c640bdaae9f458bb8b30c0717df899/6a068/patch_table_chart.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 50.625%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAKABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAgADBP/EABQBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAepDQVKT/8QAFRABAQAAAAAAAAAAAAAAAAAAEAH/2gAIAQEAAQUCY//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABYQAQEBAAAAAAAAAAAAAAAAADEAIP/aAAgBAQAGPwJnP//EABgQAQADAQAAAAAAAAAAAAAAAAEAEVEQ/9oACAEBAAE/IS8QvEp2AgGc/9oADAMBAAIAAwAAABATz//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EAB0QAAIBBAMAAAAAAAAAAAAAAAERACFBYZExUXH/2gAIAQEAAT8QIrmYvjVGW6iiQXk6iuIAEJ//2Q=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"patch table chart\" title=\"\" src=\"/static/97c640bdaae9f458bb8b30c0717df899/c08c5/patch_table_chart.jpg\" srcset=\"/static/97c640bdaae9f458bb8b30c0717df899/0913d/patch_table_chart.jpg 160w,\n/static/97c640bdaae9f458bb8b30c0717df899/cb69c/patch_table_chart.jpg 320w,\n/static/97c640bdaae9f458bb8b30c0717df899/c08c5/patch_table_chart.jpg 640w,\n/static/97c640bdaae9f458bb8b30c0717df899/6a068/patch_table_chart.jpg 960w\" sizes=\"(max-width: 640px) 100vw, 640px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n  <small>Patch tables are organized roughly like this</small>\n</center>\n<p>Sound engineers can grasp and control at once the flow of audio signals flowing between multiple complex pieces of equipment through the patch table. The concept of audio signal flow is extremely important to people controlling sound. Not only the hardware equipment I just used as an example, but even when trying to use effectors implemented in software, you ultimately need to implement this flow as is inside the program.</p>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 390px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/ee078a891d7c62fa2cd1603c31529ad2/727ba/protools.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 144.375%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAdCAIAAAAl5NuSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAFZ0lEQVR42k2Ud5PbxhnG8X1i6y7jEksWLV1hLweQYEFZ7C4aQfQOUuw8nu5ULZ3KKRPP2M7EcibfJPkjnynvyeOMMfvHbx/gWbz7bGHqzSbRNKQo5UqlWqsjTAilp+VyrV6XFYwprdZq5WpVQgpR1VqjierVGCtTQ9dbDeYfVxd/u9z/8+31i2n+/aPpT8+efHz9CvjlrPj5+dNfXn9/vZw/zZK/P3/688sXPz3ef0jCj8+ffnzx7F9PLpmVJKwta+9MvH7P5bu7CbAD4HQ54AvXCQb8hDvbWuO9684lgW80ECJj3RwOh4yAxOm6yGYJx3H8gJ+uinyRclyXH/SKVT5dFjzPc10uX2SzVTEYDttn7WSWgAVmyvihF+dBNst0XTctI53G2Sw1DNMw9XQWp9PEsixN1265iG3bpiqBD6IsjJOYeXN9/fzZy5v3H7bb7dXlFczx3bubq6tL6F6/fvPu7furq6s/8BPgN9dvX726vrn5wARhGGVumkfj8XgymaRTP05Cx3bGYzOM/CDwXdc1x6Yf+GHsARuG4fketCiKmMnYURCihGoqVGcCIFmBoinVoHJxKI/HFsEqxRomoI8lSRr2BUUmoiAxAmarrYctrspynaF8VmsfNdlKr8/1Ru1656TTL/f6bG/YabGnDbbMj846XIMdnbR7pwO5wbDD00qrdFK5W6kedwblW67erdVPW92TcqtU69yt1o9bXLnSLpUb92qtB412rT18UONKnFBlYCE9x4+gTlk2TTvwo0A3dIwh+zCIPVU3CWwtHdjXDEPBmqaHfhx4keeGjDWxHMcOoxBjeKF68Pi+rhvQ/YQ+JATsuo4fBoZpKooCafm+F4ZgtiwX3LZNCOxxDb62JxMA6N6ybf/GMNAtq+pvumkYsDQMQigIApFvEqxAkkEQiv0mhCuKousFSOCwPJJk2XU9Rewq0lAQxTBKeq0HaMQy8/n80aM5lusIiWmaLpdrRaoRIsPyL5cbgjpYGQCvVhuMzhSZh9G324tB91uNdpnlcjmfL6jSVJCUZdlqvSWoQYkcRfFqvVNxh+BhFCWb7Y5iFiMe9N354xF/39B6zGDQt22HkDaluNfrWRZMvg3T7PV405xQyqmq2O8PIHxV5SkdgQ4pCaMjQjiGUhrHcR81CMWQJPwEWNUJQkoYRCN8pqiComDYnQLhEB3JEkrjvMHfFynHgCGOk4HSBDMEFoW3rGoEAgv9SCAsVkUw+H4g0S6YBUFM4qw1+E4Cs4zkPC94dGsQBCHL8j5qaoYqCKM0TuHPRJc/GRKBdKGK4XBU5NM6/52kdhnYI0mS2q5FqaprRpbmjjuGs02JmiXAlq5rwGmSuR6suXqrpwWkYU1M5rhx94tvPv+6dFA7Kx3Xv/3y3i032AdHlXuf+E6tUzqu3v+69PkX39ypnN0rN47+8vDOn786aPZLcA3xEhKojhER+CGrEAmrimoobK+FsIioTHWZ4zsyHikEwRTYbkuUuR7P6pbEWPZe03PX22jGWiEzwyh0Y4rpktB8bM09b+14lwqZWtbcdlaaMV/vfv3rj/+9+eHfr97/h1E1H1Nb1X1RNmU0JqpLVVeSx5JsgqibgUIcYA3YCGQFrs3UCy+9cO/458xqtdjtto8v9lEUFEV2cbG/uDgvijSKQuDz812RZ3Ec7gGBiywMvd12uVrNN+s5M5s9WiyW6/UGzg0s+Gq1hgZ7EI4jiMvlCkTg3/UELjPAxRJMC2axmG82axg1DIMsS6EKaABwXEHcbjd5Dn8L/q9HYQS4WYNpwxyeSIen8mEZHTwcHByNDk8RNADoggivDo7/wEdCqXF4wv3pmP3smP3sf1kksuUwHGIfAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"protools\" title=\"\" src=\"/static/ee078a891d7c62fa2cd1603c31529ad2/727ba/protools.png\" srcset=\"/static/ee078a891d7c62fa2cd1603c31529ad2/69538/protools.png 160w,\n/static/ee078a891d7c62fa2cd1603c31529ad2/72799/protools.png 320w,\n/static/ee078a891d7c62fa2cd1603c31529ad2/727ba/protools.png 390w\" sizes=\"(max-width: 390px) 100vw, 390px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n<p>The above photo is the mixer window of <a href=\"https://www.avid.com/pro-tools\" target=\"_blank\" rel=\"nofollow\">Protools</a>, a DAW used by 90% of recording studios worldwide.</p>\n<p>Looking at the part marked <code class=\"language-text\">Vocal Bus</code> in the emphasized area, the rightmost channel is positioned at the top and the other channels are positioned at the bottom. In the <code class=\"language-text\">I/O</code> menu, the top means In and the bottom means Out, so in this picture the audio flow can be roughly represented as follows.</p>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 640px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/1f5d5ab85ca31673a0509d50c23f23f9/29114/auxes.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 56.25%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsTAAALEwEAmpwYAAABaElEQVR42mP4TwFg+P7z9/XHb68+enP10dsbT979/P2XBM1Hrz3jDZmqkDRPOm62YPj0c7ef/f/35+/ffyjg/z+IahQxoOYnbz7XLTlWv/Q4EDUsPf7m0/e/f379+UOU/Qwnbz5XTp1nUrDMtHCZWvqCS/de/vv968evHxfunTxz5+jZu8dO3z7y4es7iLXPLp27f+zAw5NH7h3e9+n5U4ZHrz9VLDhSs+hY9cKjVQuPPH/3+fePnw+e3bOrUnGoVvVo1DcqFN15dgNQ8+ePH2Y4G7WrCk4yV60XZTg6tZvh1K0XyinzDfOW6mUvVk1bcPn+q3+/f37/+R1oM9Da8/dOAG1+/+UtUPPfv3+BNj84fujR6WP3j+7/9OwJw+PXn6sXHwV6u3bJMSD5+uO3P7+J9vOx688Ew6cpJM9VSJorGjUDe2j/Qw7tvxAE5DF8+/n70v3XF+8B0avLD17//P2HhHimJIUBAF7SQPGmG4PXAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"auxes\" title=\"\" src=\"/static/1f5d5ab85ca31673a0509d50c23f23f9/6af66/auxes.png\" srcset=\"/static/1f5d5ab85ca31673a0509d50c23f23f9/69538/auxes.png 160w,\n/static/1f5d5ab85ca31673a0509d50c23f23f9/72799/auxes.png 320w,\n/static/1f5d5ab85ca31673a0509d50c23f23f9/6af66/auxes.png 640w,\n/static/1f5d5ab85ca31673a0509d50c23f23f9/d9199/auxes.png 960w,\n/static/1f5d5ab85ca31673a0509d50c23f23f9/21b4d/auxes.png 1280w,\n/static/1f5d5ab85ca31673a0509d50c23f23f9/29114/auxes.png 1920w\" sizes=\"(max-width: 640px) 100vw, 640px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n<blockquote>\n<p>At this time, each of those rectangles is exactly the same concept as nodes provided by HTML5’s Audio API. In other words, you can implement that flow perfectly identically with JavaScript.</p>\n</blockquote>\n<p>To help understanding, let me add a bit more explanation about the roles of those nodes. First, <code class=\"language-text\">Lead Vox</code> is literally a node with the vocal’s song source, and <code class=\"language-text\">LeadVxDbl</code> is a node that doubled the work - recording the same melody once more to make the song sound richer. And <code class=\"language-text\">Vox Fill</code> is a node containing chorus with harmonies stacked.</p>\n<p>And these audio sources that the vocal sang are all being gathered into a node called <code class=\"language-text\">Vocal Bus</code>. The reason for doing this is because if you use effectors on each of multiple audio sources, the sound feeling can differ slightly per node, so you gather audio signals into one node called <code class=\"language-text\">Vocal Bus</code> then only apply effectors to that node.</p>\n<p>Doing this means you don’t need to use effectors on all nodes but only on one node, so you can save memory costs and give one identical feeling to one source called vocal.</p>\n<p>And the <code class=\"language-text\">Sub Master</code> node where signals finally enter was probably created because they wanted to do effector processing once more before sound goes out to final output, and audio that reached Sub Master gets output through output - speakers - and enters our ears. Ultimately you can see it as continuous repetition of in > out > in > out. That’s why I express it as audio flow.</p>\n<p>Now that you roughly understand the flow of audio sources, let’s actually implement this flow using HTML5’s Audio API.</p>\n<h2 id=\"controlling-audio-volume\" style=\"position:relative;\">Controlling Audio Volume<a href=\"#controlling-audio-volume\" aria-label=\"controlling audio volume permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<p>As I said above, this post will focus on directly implementing and experiencing audio flow before actually implementing effectors.</p>\n<p>So I’m going to create a flow with a simple structure that’s a bit ambiguous to call an effector. The flow of controlling audio volume. Using HTML5 Audio API’s <code class=\"language-text\">GainNode</code>, you can easily control the volume of audio sources.</p>\n<h3 id=\"what-is-gain\" style=\"position:relative;\">What is Gain?<a href=\"#what-is-gain\" aria-label=\"what is gain permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<p>Simply put, gain means input volume. You use gain to control the signal amount when sending audio signals from microphones to audio mixers or recorders. People first entering audio get confused about the difference between gain and volume. Simply put, gain is “controlling input signals” and volume is “controlling output signals.”</p>\n<p>Imagine a recorder that can process signals with strength around <code class=\"language-text\">100</code>. At this time, if we shout at the microphone with strength around <code class=\"language-text\">80</code>, this recorder can accept this signal without problems, but if we shout with strength <code class=\"language-text\">150</code>, this recorder cannot accept <code class=\"language-text\">50</code> worth of sound and loses it as is.</p>\n<center>\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 640px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/f0119ca780b0c91668fc8bf38f66aefd/d44c9/clipping.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 46.25%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAIAAAC9o5sfAAAACXBIWXMAAAsRAAALEQF/ZF+RAAABpUlEQVR42j2RbW/aMBSF8///xKR9mlQhCm0gpcoySCm0lHZtWQeIJh1hQEji6zgvjkmCdyFar2zr6LHPlXyPIqWkAJQQFIeyPBwOKMqySJOkLIojRHKCeCL5fIOl4CYAQWU+0uNFnufvtu3udlVHefJjbVxX7PcnI5JS8X1vZdv283Pk7YizDFZOXpY8SazJq/XzMY4iDhB7HsKNZc0fx+vZjDPG41iITGFJEr0vQFMDQ/cadd/QeZaFk5dAbXq1M7aYE7Pnt9U0YnR0R66vUMNwEE5/k9G9kuV5sJgzswttNfyhw0WD9U1oXQT1GnS0aHiLGltTvcP6Pdo1qKEHZ9+o1oLWpZIXRRrH7KZHzmtscEua5+n0LRr0/a9fmKGzG5M06tg0uh9mf1f0+grUZtj9joK0LxUAIL5P0Nw3ydOYjO5ElgkhvI621VrkYcRmU3h9yaVMPM9tqwjp05i9TRJnqcRxhFEtLQsN280mDMOM870Qfz4+1s4SB5Zyjg9wyIyF01+TteNwzrE9LuWUaonOavz/A5Nbd1vBKryq8I+fIUsp/wEwLufZteHIRgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"clipping\" title=\"\" src=\"/static/f0119ca780b0c91668fc8bf38f66aefd/6af66/clipping.png\" srcset=\"/static/f0119ca780b0c91668fc8bf38f66aefd/69538/clipping.png 160w,\n/static/f0119ca780b0c91668fc8bf38f66aefd/72799/clipping.png 320w,\n/static/f0119ca780b0c91668fc8bf38f66aefd/6af66/clipping.png 640w,\n/static/f0119ca780b0c91668fc8bf38f66aefd/d44c9/clipping.png 722w\" sizes=\"(max-width: 640px) 100vw, 640px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n  <small>The grayed-out part is the clipped signal.</small>\n</center>\n<p>This phenomenon is one you’ve probably experienced several times in life - when you turn speaker volume really loud, you’ve heard crackling noise. This phenomenon of exceeding the signal strength equipment can handle is called clipping. Literally the signal gets clipped.</p>\n<p>This clipped signal, as you can see in the above diagram, takes the form of a square wave with a flat rectangular head, and this square wave makes the “zwaang~” metallic sound of synthesizer lead-type sounds you can hear a lot when expressing melodies in EDM, etc. Words probably don’t make sense, so let’s take a break and listen to it in music. Probably people who’ve been to clubs will say “Ah! That sound.”</p>\n<p><div class=\"gatsby-resp-iframe-wrapper\" style=\"padding-bottom: 56.49999999999999%; position: relative; height: 0; overflow: hidden; margin-bottom: 1.0725rem\" > <div class=\"embedVideo-container\"> <iframe title=\"\" src=\"https://www.youtube.com/embed/usXhiWE2Uc0?rel=0\" class=\"embedVideo-iframe\" style=\"border:0; position: absolute; top: 0; left: 0; width: 100%; height: 100%; \" loading=\"eager\" allowfullscreen=\"\" sandbox=\"allow-same-origin allow-scripts allow-popups\"></iframe> </div> </div></p>\n<center>\n  <small>From 35 seconds when that song's intro ends, the instrument taking the main melody is a lead using square waves.</small>\n  <br />\n  <br />\n</center>\n<p>Since leads are instruments so the waveform is somewhat refined, the sound when clipping occurs is rougher and sharper than this. By the way, this concept of sound changing according to waveform is a concept also used when making distortion-type effectors, so it’s good to remember.</p>\n<p>Anyway, because of this clipping problem, sound engineers place devices that can control gain between audio sources and the next equipment, and appropriately adjust gain to match the signal strength the equipment can accept, so even if the source audio’s signal gets larger, all signals can be captured.</p>\n<p>Conversely, volume means how much to amplify when outputting sound. The reason many people confuse gain and volume is because both play roles of amplifying or reducing sound, but since volume touches already input signals when outputting, if clipping occurs then reducing volume returns the signal, but sound lost due to incorrectly setting gain when recording doesn’t return.</p>\n<p>It’s already lost at the signal input stage, so it’s goodbye forever. Plus, due to the nature of recording, that original source is often a person. Ultimately, since this lost signal can’t be revived, incorrectly setting gain can lead to the sad situation of having to record again.</p>\n<p>So sound engineers think handling gain well when recording sound is extremely important. Actually even just gain has a lot more to say if you go deeper, but since this post isn’t an audio-specialized post, it’s fine to just think of them as similar and move on.</p>\n<p>Now that you understand what gain is, let’s use <code class=\"language-text\">GainNode</code> to adjust audio source signal strength and transform sound size!</p>\n<h3 id=\"lets-control-volume-using-gain-node\" style=\"position:relative;\">Let’s Control Volume Using Gain Node<a href=\"#lets-control-volume-using-gain-node\" aria-label=\"lets control volume using gain node permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h3>\n<p>First, to use gain you need an audio source. Audio sources can be obtained in two ways: using HTML5’s <code class=\"language-text\">&lt;audio></code> tag or extracting from files users directly uploaded. I used the latter method.</p>\n<p>This also, strictly speaking, creates different source node objects when extracting sources using <code class=\"language-text\">&lt;audio></code> tags versus extracting directly from file buffers, but since there’s no big functional difference, just do it according to personal preference.</p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-js line-numbers\"><code class=\"language-js\"><span class=\"token keyword\">const</span> audioContext <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token punctuation\">(</span>Audiocontext <span class=\"token operator\">||</span> webkitAudioContext<span class=\"token punctuation\">)</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\ndocument<span class=\"token punctuation\">.</span><span class=\"token function\">getElementById</span><span class=\"token punctuation\">(</span><span class=\"token string\">'audio-uploader'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function-variable function\">onchange</span> <span class=\"token operator\">=</span> <span class=\"token parameter\">evt</span> <span class=\"token operator\">=></span> <span class=\"token punctuation\">{</span>\n  <span class=\"token keyword\">const</span> file <span class=\"token operator\">=</span> evt<span class=\"token punctuation\">.</span>currentTarget<span class=\"token punctuation\">.</span>files<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">;</span>\n  <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span><span class=\"token operator\">!</span>file<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">return</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n\n  <span class=\"token keyword\">const</span> reader <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">FileReader</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  reader<span class=\"token punctuation\">.</span><span class=\"token function-variable function\">onload</span> <span class=\"token operator\">=</span> <span class=\"token keyword\">async</span> <span class=\"token parameter\">evt</span> <span class=\"token operator\">=></span> <span class=\"token punctuation\">{</span>\n    <span class=\"token keyword\">const</span> buffer <span class=\"token operator\">=</span> <span class=\"token keyword\">await</span> audioContext<span class=\"token punctuation\">.</span><span class=\"token function\">decodeAudioData</span><span class=\"token punctuation\">(</span>file<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">const</span> sourceNode <span class=\"token operator\">=</span> audioContext<span class=\"token punctuation\">.</span><span class=\"token function\">createBufferSource</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    sourceNode<span class=\"token punctuation\">.</span>buffer <span class=\"token operator\">=</span> buffer<span class=\"token punctuation\">;</span>\n    console<span class=\"token punctuation\">.</span><span class=\"token function\">log</span><span class=\"token punctuation\">(</span>sourceNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-js line-numbers\"><code class=\"language-js\">AudioBufferSourceNode <span class=\"token punctuation\">{</span><span class=\"token literal-property property\">buffer</span><span class=\"token operator\">:</span> AudioBuffer<span class=\"token punctuation\">,</span> <span class=\"token literal-property property\">playbackRate</span><span class=\"token operator\">:</span> AudioParam<span class=\"token punctuation\">,</span> <span class=\"token literal-property property\">detune</span><span class=\"token operator\">:</span> AudioParam<span class=\"token punctuation\">,</span> <span class=\"token literal-property property\">loop</span><span class=\"token operator\">:</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">,</span> <span class=\"token literal-property property\">loopStart</span><span class=\"token operator\">:</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span> …<span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<p>First, a simple explanation: the audio data contained in the <code class=\"language-text\">buffer</code> variable is just raw audio data and isn’t yet a node so it’s unusable. Therefore, only after creating a source node using the <code class=\"language-text\">createBufferSource</code> method and inputting audio data into that source node does the audio data become usable.</p>\n<p>At this time, since I extracted audio buffer data directly from files users uploaded and made nodes, I used the <code class=\"language-text\">createBufferSource</code> method to create source nodes, but if you want to create source nodes using audio data extracted from <code class=\"language-text\">&lt;audio></code> tags, you should use the <code class=\"language-text\">createMediaElementSource</code> method.</p>\n<p>Now if you just create a <code class=\"language-text\">GainNode</code> and connect it to the source node, you can immediately control this audio source’s volume.</p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-js line-numbers\"><code class=\"language-js\"><span class=\"token keyword\">const</span> gainNode <span class=\"token operator\">=</span> audioContext<span class=\"token punctuation\">.</span><span class=\"token function\">createGain</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\nsourceNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>gainNode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\ngainNode<span class=\"token punctuation\">.</span><span class=\"token function\">connect</span><span class=\"token punctuation\">(</span>audioContext<span class=\"token punctuation\">.</span>destination<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span></span></pre></div>\n<p>If you can see the audio flow set as source > gain node > destination in this code, you can say understanding of Audio API is pretty much finished. As I said above, this concept is most important when controlling audio.</p>\n<p>Also, <code class=\"language-text\">audioContext.destination</code> that <code class=\"language-text\">gainNode</code> is connected to has information heading to final output - speakers. So now, how should we amplify or reduce audio sound here?</p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-js line-numbers\"><code class=\"language-js\">gainNode<span class=\"token punctuation\">.</span>gain<span class=\"token punctuation\">.</span>value <span class=\"token operator\">=</span> <span class=\"token number\">1.2</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">// or</span>\ngainNode<span class=\"token punctuation\">.</span>gain<span class=\"token punctuation\">.</span><span class=\"token function\">setValueAtTime</span><span class=\"token punctuation\">(</span><span class=\"token number\">1.2</span><span class=\"token punctuation\">,</span> audioContext<span class=\"token punctuation\">.</span>currentTime<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">// Then let's play the source</span>\nsourceNode<span class=\"token punctuation\">.</span><span class=\"token function\">start</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<blockquote>\n<p>[Warning] If you raise the value too much, your eardrums will burst when playing.</p>\n</blockquote>\n<p>Simple. Just access <code class=\"language-text\">GainNode.gain.value</code> and change the value. For gain, directly accessing and changing values is possible, but for other nodes there are cases where directly changing their values isn’t allowed. In such cases, use the <code class=\"language-text\">setValueAtTime</code> method.</p>\n<p>The <code class=\"language-text\">setValueAtTime</code> method is a kind of scheduler concept - it has the function of applying values after the time passed as the second argument. The unit of time passed as an argument here is seconds. Using <code class=\"language-text\">audioContext.currentTime</code> as an argument applies value changes immediately.</p>\n<p>One thing I was confused about when first changing these nodes’ values was the minimum and maximum values that can be input to nodes. In other words, I couldn’t know the range of values this node has. Of course it’s all in the official documentation, but who has time to search and read that one by one?</p>\n<p>So digging a bit more into the documentation, I could see that values these nodes have are commonly <code class=\"language-text\">AudioParam</code> type. This type has <code class=\"language-text\">min</code>, <code class=\"language-text\">max</code>, <code class=\"language-text\">defaultValue</code>, <code class=\"language-text\">value</code> properties, and these values can be usefully used when controlling audio using <code class=\"language-text\">input[type=\"range\"]</code>.</p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-js line-numbers\"><code class=\"language-js\">console<span class=\"token punctuation\">.</span><span class=\"token function\">log</span><span class=\"token punctuation\">(</span>gainNode<span class=\"token punctuation\">.</span>gain<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre style=\"counter-reset: linenumber NaN\" class=\"language-js line-numbers\"><code class=\"language-js\">AudioParam <span class=\"token punctuation\">{</span><span class=\"token literal-property property\">value</span><span class=\"token operator\">:</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token literal-property property\">automationRate</span><span class=\"token operator\">:</span> <span class=\"token string\">\"a-rate\"</span><span class=\"token punctuation\">,</span> <span class=\"token literal-property property\">defaultValue</span><span class=\"token operator\">:</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token literal-property property\">minValue</span><span class=\"token operator\">:</span> <span class=\"token operator\">-</span><span class=\"token number\">3.4028234663852886e+38</span><span class=\"token punctuation\">,</span> <span class=\"token literal-property property\">maxValue</span><span class=\"token operator\">:</span> <span class=\"token number\">3.4028234663852886e+38</span><span class=\"token punctuation\">}</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span></span></pre></div>\n<p>If you check this value well and set the gain value, you can at least prevent the unfortunate accident of eardrums and earphones bursting. As I said above, if you exceed the signal strength the computer can handle, clipping occurs and tearing sounds happen, so if you were wearing earphones, not joking, your ears could really get damaged.</p>\n<p>Okay, I’ve simply adjusted the gain of audio sources like this. Most other effectors are also implemented in this kind of feeling. Occasionally there are effectors that need slightly more complex connections, but in most cases they can be implemented just by connecting a few simple nodes, so they’re not that difficult.</p>\n<p>In the <a href=\"/2019/08/21/javascript-audio-effectors-practice/\">next post</a>, based on the concepts we learned this time, I’ll create other effectors that can compress sound, give spatial feeling, and cut specific frequencies to give sound a special feeling.</p>\n<p>Also, if there’s a chance, I plan to proceed with a post where I can create my own instrument using an oscillator that can actually generate audio signals themselves, not effectors that transform already existing audio sources.</p>\n<p>That’s all for this post on building JavaScript audio effectors - understanding audio flow.</p>","fields":{"slug":"20190819-javascript-audio-effectors-gain-en","path":"/2019/08/19/javascript-audio-effectors-gain/en/","lang":"en"},"frontmatter":{"title":"[Building JavaScript Audio Effectors] Understanding Audio Flow","subTitle":"Audio Effector Development Starting from GainNode","date":"Aug 19, 2019","categories":["Programming","Audio"],"tags":["JavaScript","Audio","Audio Effectors","JavaScript Audio API","Logic Pro X","Protools","Cubase","Audio Plugin","Compressor","Delay","Reverb","EQ"],"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","images":{"fallback":{"src":"/static/026a9fe9c894f201ec1e45217221447c/3a812/thumbnail.jpg","srcSet":"/static/026a9fe9c894f201ec1e45217221447c/3a812/thumbnail.jpg 320w,\n/static/026a9fe9c894f201ec1e45217221447c/4b287/thumbnail.jpg 750w","sizes":"(min-width: 320px) 320px, 100vw"},"sources":[{"srcSet":"/static/026a9fe9c894f201ec1e45217221447c/fc5c5/thumbnail.webp 320w,\n/static/026a9fe9c894f201ec1e45217221447c/e9225/thumbnail.webp 750w","type":"image/webp","sizes":"(min-width: 320px) 320px, 100vw"}]},"width":320,"height":320}}},"jumbotron":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","images":{"fallback":{"src":"/static/026a9fe9c894f201ec1e45217221447c/2d839/thumbnail.jpg","srcSet":"/static/026a9fe9c894f201ec1e45217221447c/2d839/thumbnail.jpg 750w","sizes":"100vw"},"sources":[{"srcSet":"/static/026a9fe9c894f201ec1e45217221447c/b384d/thumbnail.webp 750w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5}}}}}}]}},"pageContext":{"tag":"Audio","lang":"en"}},"staticQueryHashes":["3523904809","650499039"],"slicesMap":{}}