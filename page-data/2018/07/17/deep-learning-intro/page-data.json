{"componentChunkName":"component---src-templates-post-tsx","path":"/2018/07/17/deep-learning-intro/","result":{"data":{"markdownRemark":{"id":"8eda2166-3a3a-521d-abd6-19e07a51c310","excerpt":"이번 포스팅에서는 딥러닝이 무엇인지, 기존의 뉴럴네트워크와 다른 점이 무엇인지에 대해서 포스팅하려고 한다.","html":"<p>이번 포스팅에서는 딥러닝이 무엇인지, 기존의 뉴럴네트워크와 다른 점이 무엇인지에 대해서 포스팅하려고 한다.</p>\n<!-- more -->\n<h2 id=\"artificial-neural-network란\" style=\"position:relative;\">Artificial Neural Network란?<a href=\"#artificial-neural-network%EB%9E%80\" aria-label=\"artificial neural network란 permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<p>인류는 과거부터 생각하는 기계를 만드려는 노력을 해왔다. 그 과정에서 다양한 시도들이 있었고, 결국 고안해낸 방법은 <strong>인간의 뇌를 프로그래밍</strong>해보자는 것이였다. 이런 발상이 가능했던 것은 현대에 이르러 인간의 뇌의 구조를 어느 정도 알 수 있었기 때문이기도 하고 이 구조가 생각보다 단순하다는 점도 있었다.</p>\n<center>\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 640px;\">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/3823b410149889c0e9aefb86b3f6e80e/21b4d/neural.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 53.75%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAAsSAAALEgHS3X78AAABwUlEQVQoz32Sy2/aQBDG+c97rRTl0kt7yKWV+oiUVClJ06qFkOBAA4UARrsmfmBwgoNfGPy22bU7sLSqKqVzGO2u5vftfDtbyvO8KArf90RRRAit1+viv0EIiaIoSZIsy0oMjuN4Pp9DhjU7eSqAlGUFY6zregn2lm1fXjS5ehPETNN2nAWT+KPCFg/3j53WQEAiRiKlBE42sKY9nJdrJ0fVi8r1uzfl4UDQtKm8jdVqBUbSNIXsB0mt0ikfVyzThrZ3cBTGaCidHTf4/uj66qe7cKMogGpKKRRJkiQIWBiJyuj266cv56fcoIeYwQ18N1JAW1Ue+22l20JJmrJmf9vM03UBZsbcM0u/M61l+6YHz7aD8XDMXXYaNf7Vy88fXrf5xjdjeLCyRJJ6hGR5TnxbxvV9877LtOI4IYTu4IUDYv2bOt7bf//xiFNFbCjfNXSqtl6o/KHafK703jqzQZjQGPxsg010A5uGdXZSrVWb3R+ocdWdTnXdWJr2ctt5FngLMA9lkD3Pm0wm8JCu6+5gUFLVSe+W9/3Asd3ADwFj2n4QSvIYvoBpzCn9d/4bGMTCMHzqS8xmM2cb7P6/5/8LNp9d05eLIeQAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"neural\" title=\"neural\" src=\"/static/3823b410149889c0e9aefb86b3f6e80e/6af66/neural.png\" srcset=\"/static/3823b410149889c0e9aefb86b3f6e80e/69538/neural.png 160w,\n/static/3823b410149889c0e9aefb86b3f6e80e/72799/neural.png 320w,\n/static/3823b410149889c0e9aefb86b3f6e80e/6af66/neural.png 640w,\n/static/3823b410149889c0e9aefb86b3f6e80e/d9199/neural.png 960w,\n/static/3823b410149889c0e9aefb86b3f6e80e/21b4d/neural.png 1280w\" sizes=\"(max-width: 640px) 100vw, 640px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n  </a>\n    </span>\n  <br>\n</center>\n<p>인간의 뇌는 이 <code class=\"language-text\">뉴런</code>이라고 불리는 세포들의 집합체이다. 이 <code class=\"language-text\">뉴런</code>들은 그냥 어떠한 신호를 받은 후에 변조한 다음 다시 전달하는 세포인데, 뇌는 결국 이 뉴런들이 그물망처럼 연결되어있는 구조인 것이다.\n결론적으로 인간의 뇌의 구조는 굉장히 복잡하게 <code class=\"language-text\">연결</code>되어있지만 그 <code class=\"language-text\">연결체</code>인 뉴런 자체는 놀랍도록 단순한 구조로 되어있었다는 것이 된다.</p>\n<p>이 <code class=\"language-text\">뉴런</code>들은 <code class=\"language-text\">수상돌기</code>에서 input신호를 받아 <code class=\"language-text\">축색돌기</code>로 output신호를 전송하는 구조인데 이때 다음 <code class=\"language-text\">뉴런</code>으로 신호가 전달되기 위해서는 일정 기준, 즉 <code class=\"language-text\">threshold</code> 이상의 전기 신호를 넘겨야한다. 좀 더 자세히 알아보자면 대략 다음 순서를 따른다고 한다.</p>\n<hr>\n<ol>\n<li>뉴런에 연결되어 있는 여러 개의 시냅스로 부터 신호를 받는다.\n이때 신호는 분비된 화학물질의 양(<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">x</span></span></span></span>)과 분비되는 시간(<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>w</mi></mrow><annotation encoding=\"application/x-tex\">w</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span></span>)의 곱으로 나타내어 질 수 있다.</li>\n<li>여러 개의 시냅스로부터 받은 여러 개의 신호를 합친다.</li>\n<li>다음 시냅스로 전달하기 전에 특정한 값(<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">b</span></span></span></span>)이 더해진다.</li>\n<li>이 값이 특정 임계점을 넘어가면 신호가 다음 시냅스로 전달된다.</li>\n</ol>\n<hr>\n<center>\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 512px;\">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/6d395b79311597e65462e2af18844938/36dd4/hoe.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAECAwX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAHvZXoaoCwQD//EABkQAQADAQEAAAAAAAAAAAAAAAEAETFBAv/aAAgBAQABBQJg+oNneBQ7DP/EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQMBAT8BH//EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQIBAT8BH//EABsQAAIBBQAAAAAAAAAAAAAAAAABIRARIDGB/9oACAEBAAY/AhX6RTTh4I//xAAdEAEAAgICAwAAAAAAAAAAAAABABEhMRBBUYGh/9oACAEBAAE/IVRAFw0Z9wAVYxvXcNtHYdTEY9FQCb8cfNP/2gAMAwEAAgADAAAAEJPAAP/EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQMBAT8QH//EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQIBAT8QH//EAB8QAQADAAEEAwAAAAAAAAAAAAEAESExQVFhoXGx8P/aAAgBAQABPxAdGl4htZignyCtgJAWJDY6FULVnX94IrEsJkeSdzZzRF5gCCouknqVldJ6D6n/2Q==&apos;); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"hoe\" title=\"hoe\" src=\"/static/6d395b79311597e65462e2af18844938/36dd4/hoe.jpg\" srcset=\"/static/6d395b79311597e65462e2af18844938/0913d/hoe.jpg 160w,\n/static/6d395b79311597e65462e2af18844938/cb69c/hoe.jpg 320w,\n/static/6d395b79311597e65462e2af18844938/36dd4/hoe.jpg 512w\" sizes=\"(max-width: 512px) 100vw, 512px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n  </a>\n    </span>\n  <small>&#xC5B4;&#xB77C;...? &#xC0DD;&#xAC01;&#xBCF4;&#xB2E4; &#xC2EC;&#xD50C;&#xD55C;&#xB370;...?</small>\n</center>\n<p>사람의 뇌가 이렇게 간단한 원리도 작동한다니…그럼 이걸 기계로도 만들 수 있지 않을까? 라는데서 출발한 것이 바로 <code class=\"language-text\">Artificial Neural Network</code>인 것이다. 이러한 뉴런의 작동방식은 다음과 같이 도식화 될 수 있다.</p>\n<center>\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 640px;\">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/500df46f498950f6283ef37cc89af689/aeb8d/artificial-neural-network.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 50.625%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAKABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAd5FCKD/xAAWEAEBAQAAAAAAAAAAAAAAAAAQATH/2gAIAQEAAQUCbh//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAZEAACAwEAAAAAAAAAAAAAAAAAIRARMVH/2gAIAQEAAT8hG6Hw3n//2gAMAwEAAgADAAAAEPMP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAGxAAAgIDAQAAAAAAAAAAAAAAAREAITFRkRD/2gAIAQEAAT8QZOxyEui1ROI9XZUoorMGB5//2Q==&apos;); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"artificial neural network\" title=\"artificial neural network\" src=\"/static/500df46f498950f6283ef37cc89af689/c08c5/artificial-neural-network.jpg\" srcset=\"/static/500df46f498950f6283ef37cc89af689/0913d/artificial-neural-network.jpg 160w,\n/static/500df46f498950f6283ef37cc89af689/cb69c/artificial-neural-network.jpg 320w,\n/static/500df46f498950f6283ef37cc89af689/c08c5/artificial-neural-network.jpg 640w,\n/static/500df46f498950f6283ef37cc89af689/aeb8d/artificial-neural-network.jpg 651w\" sizes=\"(max-width: 640px) 100vw, 640px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n  </a>\n    </span>\n  <br>\n</center>\n<p>이 도식을 다시 수식으로 나타내면 다음과 같다.</p>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>x</mi><mi>i</mi></msub><msub><mi>w</mi><mi>i</mi></msub><mo>+</mo><mi>b</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">  f(\\sum\\limits_{i=1}^n x_i w_i + b)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.929066em;vertical-align:-1.277669em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.6513970000000002em;\"><span style=\"top:-1.872331em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.050005em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span><span style=\"top:-4.3000050000000005em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">n</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.277669em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">b</span><span class=\"mclose\">)</span></span></span></span></span>\n<p>이때 이 함수 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi></mrow><annotation encoding=\"application/x-tex\">f</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span></span></span></span>를 <code class=\"language-text\">Activation Funcntion</code>이라고 하며, 이 함수는 함수 내부의 값이 <code class=\"language-text\">threshold</code>를 넘어가면 <code class=\"language-text\">1</code>을 리턴하고 아니면 <code class=\"language-text\">0</code>을 리턴하는 함수이다.</p>\n<p>이것이 하나의 <code class=\"language-text\">뉴런</code>이라고 생각하면 이 <code class=\"language-text\">뉴런</code>을 여러 개 모아본다면 대략 아래와 같은 구조가 될 것이다.</p>\n<center>\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 520px;\">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/8c5079be24758bf721e5270eaa520a7b/ddb38/single-layer-network.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 100.62500000000001%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAECAwX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAHuZ3oaggFwf//EABkQAAMAAwAAAAAAAAAAAAAAAAACMQEQIf/aAAgBAQABBQIaabmBY0P/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/AR//xAAZEAACAwEAAAAAAAAAAAAAAAAQMQARIEH/2gAIAQEABj8CHQ6jx//EABwQAQADAAIDAAAAAAAAAAAAAAEAESExURBhwf/aAAgBAQABPyFaXmO9WnRMoyHV2/k7D2JZku/DOCf/2gAMAwEAAgADAAAAEHAHAP/EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQMBAT8QH//EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQIBAT8QH//EAB0QAAIDAAMBAQAAAAAAAAAAAAERACExQVGBkaH/2gAIAQEAAT8QYgt2C15ALtL0M8AOTKoGhw5AADAeLXyUYUOrhiMk3yXK8t7n5p//2Q==&apos;); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"single layer network\" title=\"single layer network\" src=\"/static/8c5079be24758bf721e5270eaa520a7b/ddb38/single-layer-network.jpg\" srcset=\"/static/8c5079be24758bf721e5270eaa520a7b/0913d/single-layer-network.jpg 160w,\n/static/8c5079be24758bf721e5270eaa520a7b/cb69c/single-layer-network.jpg 320w,\n/static/8c5079be24758bf721e5270eaa520a7b/ddb38/single-layer-network.jpg 520w\" sizes=\"(max-width: 520px) 100vw, 520px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n  </a>\n    </span>\n  <br>\n</center>\n<p>그리고 이런 형태의 기계는 이미 1950년대에 개발되어 <code class=\"language-text\">AND</code>나 <code class=\"language-text\">OR</code>문제 같은 선형방정식은 풀 수 있을 정도였다.</p>\n<h2 id=\"암흑기의-도래\" style=\"position:relative;\">암흑기의 도래<a href=\"#%EC%95%94%ED%9D%91%EA%B8%B0%EC%9D%98-%EB%8F%84%EB%9E%98\" aria-label=\"암흑기의 도래 permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<p>자 그럼 여기서 한가지 의문이 생긴다.</p>\n<blockquote>\n<p><em>아니 지금은 21세기하고도 18년이나 지난 2018년인데, 1950년대에 이미 저기까지 개발이 됐으면 지금은 로봇이 나 대신 일도 해주고 어? 빨래도 해주고 어? 해야하는 거 아니냐!</em></p>\n</blockquote>\n<p>하는 생각이 들 수도 있다. 우선 아까 말한 <code class=\"language-text\">AND</code>와 <code class=\"language-text\">OR</code>를 다시 보자.</p>\n<center>\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 301px;\">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/f87f23e2080e37f8112b3b9c36b731fe/fb933/or.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 111.25%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAWCAYAAADAQbwGAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABa0lEQVQ4y62VvU7DMBDHLyU0Qf0iEaVqkRDlS1AVEDAxISR2JgaeCHXhMXgakNhY4AmQGBhQh1L4X30msWlRnPSkv+4ax7+cffaVKJstQXXIpznYInQNDaA9eeYVhbagjmSa2WLXCf/ZEbQFVWSf6ta4N2OZnEB1GvAUWpW4CfUy7tUatGu8q8sGHzXnuGS2ZWihMOVeUr0l6j4RbXP8Is8+obEr8DwJo2ei4294UiBPvDtUrIF9DADsD4lqNjSzlZL6x3IraISqA1JOw/JkGW0ShRwgwwoAByMrQ1co711AyeQGdEgWbJwH+Cg7gcktaF+DvvIC2d6T5XYB2kgXKQ9wcsBfBQDgDrTO8YcJDeX+z+w2vlS6Zg/iOPX0GR1Ov8t/rCryJMOJ2uojpQv4N6KTB/VhTtdPNQ/fvrYMupKOsyId51eh8jFaUmegKh8H5jttaX9GY7gs8Bdx5jRDt7gb6E6WWTaH+/rHD4XFOQlJtT0bAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"or\" title=\"or\" src=\"/static/f87f23e2080e37f8112b3b9c36b731fe/fb933/or.png\" srcset=\"/static/f87f23e2080e37f8112b3b9c36b731fe/69538/or.png 160w,\n/static/f87f23e2080e37f8112b3b9c36b731fe/fb933/or.png 301w\" sizes=\"(max-width: 301px) 100vw, 301px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n  </a>\n    </span>\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 314px;\">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/8f39aacbb882bcd4bc1eb9e0b43e1935/5b158/and.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 105.62500000000001%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAVCAYAAABG1c6oAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABQ0lEQVQ4y6WU4U7CMBDHb8MCKkOQgRoNccQPBEiIwcRvPhAJ4QV8Xx/ADxqjxX/djbR17Tq45J/ruuy3u2vviPx2Dp1BPahJR1oHWkMb6BVa8H50KFAgvAv4S+gGatX5+A6Ki4f4yNReoBF0ouo0IWqozQ/U75NorNZb/kfbrO21C/gAdbk2nUYO/jNJNIFuea3XLoHufVEO9Uw32guAFjKvI+1qHEhaAAvqlwmdyfyA9tCoAp7qEUrL/+Ad1kt4wc/E8DCgBY3Ynyro+/+fhQEd0ASauzKpBDqgV4hqWuypCL9LoF6gDQVkDGW+KFNfg8jyg8pk3mH1Uiar+Opk38zrlNSO0LadGb0oAw7ZqxYUIZNI8EV33cc+93JQa40qhpKadU/QgFNPOeIqDdhnNvAZWmmjMAoQ8bh7DCxRkMWcmWG/ZdhIs0T5sBgAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"and\" title=\"and\" src=\"/static/8f39aacbb882bcd4bc1eb9e0b43e1935/5b158/and.png\" srcset=\"/static/8f39aacbb882bcd4bc1eb9e0b43e1935/69538/and.png 160w,\n/static/8f39aacbb882bcd4bc1eb9e0b43e1935/5b158/and.png 314w\" sizes=\"(max-width: 314px) 100vw, 314px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n  </a>\n    </span>\n</center>\n<p><code class=\"language-text\">AND</code>와 <code class=\"language-text\">OR</code>는 선형방정식이기 때문에 1950년대에 개발한 <code class=\"language-text\">Single Layer Network</code>를 적용한 기계로도 이런 문제를 푸는 건 별로 어렵지 않았다.</p>\n<p>여기까지 성공한 사람들은 <strong>대박이다. 이제 금방 기계가 걷고 뛰고 말도 할 수 있겠구나!</strong> 라고 생각했지만.. <code class=\"language-text\">XOR</code>가 등장하면 어떨까?</p>\n<center>\n  <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 281px;\">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/c0b2a78291b2791a491b0e6ccd63d2d3/6b1e2/xor.png\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 104.375%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAVCAYAAABG1c6oAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAA+klEQVQ4y62VSwrCMBCG09r6KiIVrQ/cKLrwdQDBjXgF0SMI3sC9t/GMRv/gRMZaa5N24COThP6ZybRTIf6bB8qgDqrAFZbm0DgDF3ACVzCI7RtbE0zBHIxBkPXBQBRkKoIhpZaWvpM1TZXGDtRovgQTg3tqA58vuFTBDs1VJSsGGXpJB5eYYCHmJwmemS+RiaRI7vQeGQuSUOrcSFB++luw0usyj6BKFRzATb6KZieo747GDTiyA+wiZIJ7sNCCIoeg9nuglesOfxTHvsqxwrz9Rx5Bg775JRix7tPI0Bz03poF4/BvObSMMPGXEFJHVlF2DYkowhHoPwHLpDCbyS0HZgAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"xor\" title=\"xor\" src=\"/static/c0b2a78291b2791a491b0e6ccd63d2d3/6b1e2/xor.png\" srcset=\"/static/c0b2a78291b2791a491b0e6ccd63d2d3/69538/xor.png 160w,\n/static/c0b2a78291b2791a491b0e6ccd63d2d3/6b1e2/xor.png 281w\" sizes=\"(max-width: 281px) 100vw, 281px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n  </a>\n    </span>\n  <br>\n</center>\n<p>와 이건 어떻게 선을 그어도 도저히 답이 없다. <code class=\"language-text\">XOR</code>는 두개의 인풋이 <code class=\"language-text\">같지 않으면 true</code>인 논리식이다. 굉장히 단순해보였지만 <code class=\"language-text\">XOR</code>는 선형방정식이 아니기 때문에 직선으로는 50%의 정확도밖에 낼 수 없었다. 여기까지 직면한 사람들은 좌절하게 된다.</p>\n<blockquote>\n<p>We need to use MLP, Multi Layer Perceptrons.\nNo one on earth had found a viable way to train MLPs good enough to learn such simple functions.</p>\n<p><strong>Perceptrons(1969)</strong> <em>Marvin Minsky</em></p>\n</blockquote>\n<p>결국 1969년 <strong>Marvin Minsky</strong> 가 <code class=\"language-text\">Single Layer Network</code>로는 <code class=\"language-text\">XOR</code>문제를 풀 수 없다는 것을 수학적으로 증명한다. <code class=\"language-text\">Multi Layer Network</code>로는 가능한데 아무도 학습시킬 수 없다고 했단다.</p>\n<p>이 이유에 대해서 좀 더 알아보고 싶어서 <code class=\"language-text\">Perceptrons</code>의 구문을 찾아보니</p>\n<blockquote>\n<p>it ought to be possible to devise a training alhorithm to optimize the weights in thie using, say, the magnitude of a reinforcement signal to communicate to the net the cost of an error. We have not investigated this.</p>\n<p><strong>Perceptrons(1969)</strong> <em>Marvin Minsky</em></p>\n</blockquote>\n<p>라고 한다. 구글링 하다보니까 <code class=\"language-text\">Perceptrons</code>라는 책은 <code class=\"language-text\">XOR</code>가 <code class=\"language-text\">Single Layer Network</code>로 왜 학습이 안되는 지에 대해서 집중적으로 설명하고나서</p>\n<blockquote>\n<p>어…음 Multi Layer Network로 학습시키면 되는 건 알겠는데 어떻게 해야하는 지는 아직 잘 모르겠다.</p>\n</blockquote>\n<p>정도로 쓴 책이라는 의견도 있었다.\n어찌됐던 이 책으로 인해 많은 사람들이 실망을 하게 되고 이로 인해 <code class=\"language-text\">Neural Network</code>라는 학문 자체가 암흑기에 빠지게 된다.</p>\n<h2 id=\"다시-재기의-시간\" style=\"position:relative;\">다시 재기의 시간<a href=\"#%EB%8B%A4%EC%8B%9C-%EC%9E%AC%EA%B8%B0%EC%9D%98-%EC%8B%9C%EA%B0%84\" aria-label=\"다시 재기의 시간 permalink\" class=\"anchor after\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a></h2>\n<p>1974년 <strong>Paul Werbos</strong> 는 자신의 박사학위 논문에 <code class=\"language-text\">Backpropagation</code>이라는 알고리즘을 게재하게 된다.</p>\n<p>그러나 슬프게도 아무도 관심을 가지지 않았고 심지어 <code class=\"language-text\">Perceptrons</code>의 저자인 <strong>Marvin Minsky</strong> 마저도 관심을 안가져줬다고 한다. 심지어 1982년도에 다시 논문을 발표하게 됐는데 이때도 그냥 묻혔다고 한다…</p>\n<p>그러다가 1986년, <strong>Geoffrey Hinton</strong> 이 독자적으로 이 알고리즘을 다시 발견하고 발표하게 되면서 주목을 받게된다. 어쨋든 이 알고리즘으로 인해 <code class=\"language-text\">Multi Layer Network</code>의 학습이 가능하다는 사실이 알려지고 다시 <code class=\"language-text\">Neural Network</code> 학문은 활기를 띄게 된다.</p>\n<p><code class=\"language-text\">Backpropagation</code>이라는 알고리즘의 구조는 간단하다. 그냥 말 그대로 에러를 output에서 가까운 쪽부터 뒤로(Back) 전파(Propagation)하는 것이다. 그래서 <code class=\"language-text\">역전파알고리즘</code>이라고도 불린다.\n이 <code class=\"language-text\">Backpropagation</code>에 대해서는 <a href=\"/2018/07/19/deep-learning-backpropagation\">다음 포스팅</a>에서 다시 다루도록 하겠다.</p>\n<p>이상으로 Deep Learning 첫번째 포스팅을 마친다.</p>","tableOfContents":"<ul>\n<li><a href=\"#artificial-neural-network%EB%9E%80\">Artificial Neural Network란?</a></li>\n<li><a href=\"#%EC%95%94%ED%9D%91%EA%B8%B0%EC%9D%98-%EB%8F%84%EB%9E%98\">암흑기의 도래</a></li>\n<li><a href=\"#%EB%8B%A4%EC%8B%9C-%EC%9E%AC%EA%B8%B0%EC%9D%98-%EC%8B%9C%EA%B0%84\">다시 재기의 시간</a></li>\n</ul>","fields":{"lang":"ko"},"frontmatter":{"title":"[Deep Learning이란 무엇인가?] 딥러닝이란?","date":"2018-07-17","categories":["Programming","Machine Learning"],"tags":["머신러닝","딥러닝","Machine Learning","Deep Learning"],"thumbnail":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAQABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAgAF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB3iiKo//EABcQAQADAAAAAAAAAAAAAAAAABAAESH/2gAIAQEAAQUCmtH/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAWEAADAAAAAAAAAAAAAAAAAAAAIDH/2gAIAQEABj8CIv8A/8QAGxAAAgIDAQAAAAAAAAAAAAAAAAERIVFxkcH/2gAIAQEAAT8hbgm3oVojo1jOxUj/2gAMAwEAAgADAAAAECPP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAGRABAQEBAQEAAAAAAAAAAAAAAREhADFx/9oACAEBAAE/EPIY/OTMiOXCcgE05rSESzsRFxKri8IHvf/Z","aspectRatio":1.2820512820512822,"src":"/static/26718e1f085d210bba3e45681f40c1fa/14b42/thumbnail.jpg","srcSet":"/static/26718e1f085d210bba3e45681f40c1fa/f836f/thumbnail.jpg 200w,\n/static/26718e1f085d210bba3e45681f40c1fa/2244e/thumbnail.jpg 400w,\n/static/26718e1f085d210bba3e45681f40c1fa/14b42/thumbnail.jpg 800w,\n/static/26718e1f085d210bba3e45681f40c1fa/a7715/thumbnail.jpg 1000w","sizes":"(max-width: 800px) 100vw, 800px"}}}}},"allMarkdownRemark":{"edges":[]}},"pageContext":{"slug":"/20180717-deep-learning-intro/","previous":{"fields":{"slug":"/20170514-paypal-express-checkout/","path":"/2017/05/14/paypal-express-checkout/","lang":"ko","postGroup":"20170514-paypal-express-checkout"},"frontmatter":{"title":"Paypal - Express Checkout Restful API 사용하기"}},"next":{"fields":{"slug":"/20180719-deep-learning-backpropagation/","path":"/2018/07/19/deep-learning-backpropagation/","lang":"ko","postGroup":"20180719-deep-learning-backpropagation"},"frontmatter":{"title":"[Deep Learning이란 무엇인가?] Backpropagation, 역전파 알아보기"}},"lang":"ko","postGroup":"20180717-deep-learning-intro"}}}